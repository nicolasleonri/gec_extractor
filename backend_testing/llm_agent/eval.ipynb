{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "- Process all LLM models with both methods, store responses in 'JSON' and 'SQL' folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def write_first_element_to_txt(csv_file_path, txt_file_path):\n",
    "    with open(csv_file_path, mode='r', newline='') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        with open(txt_file_path, mode='w') as txt_file:\n",
    "            for row in reader:\n",
    "                if len(row) > 0:  # Ensure there's at least one element in the row\n",
    "                    txt_file.write(row[0] + '\\n')\n",
    "\n",
    "# write_first_element_to_txt('evaluation_files/.csv', 'output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_1 = [\n",
    "    \"What was my hemoglobin level in the most recent report?\",\n",
    "    \"What medications am I currently prescribed, and what are their dosages?\",\n",
    "    \"Which hospital did I last visit for my medical visit?\",\n",
    "    \"What was the result of my last cholesterol test?\",\n",
    "    \"How many times have I been diagnosed with hypertension?\",\n",
    "    \"What are the recommendations for managing my diabetes?\",\n",
    "    \"What is the contact number of the hospital where I had my last appointment?\",\n",
    "    \"What was the total payment for my last medical appointment?\",\n",
    "    \"What diagnosis was given by Dr. Jane Doe during my last visit?\",\n",
    "    \"What are the normal reference ranges for a glucose test?\",\n",
    "    \"How often should I take my prescribed Lisinopril?\",\n",
    "    \"What was the interpretation of my last creatinine test result?\",\n",
    "    \"What are the tests for which I have a high interpretation?\",\n",
    "    \"Which is recommended for my allergy diagnosis?\",\n",
    "    \"What is the dosage of the medicine Oseltamivir?\",\n",
    "    \"Can you provide the address of the Kindred Hospital I visited in Chicago?\",\n",
    "    \"What was my platelet count in the most recent blood report?\",\n",
    "    \"Who diagnosed me with flu last year?\",\n",
    "    \"What are the dates of the appointments I have with Dr. Michael Smith?\",\n",
    "    \"How much did I pay for my medical appointments?\",\n",
    "    \"What is the dosage and frequency for the medicine Metformin that I am taking?\",\n",
    "    \"Can you list all the doctors I have seen at the 4th hospital in Miami?\",\n",
    "    \"What recommendations were given for my last diagnosis of gastritis?\",\n",
    "    \"How many times have I been prescribed Cetirizine?\",\n",
    "    \"What was the result of my urinalysis report from two visits ago?\",\n",
    "    \"Can you provide a summary of my medical reports from the last six months?\",\n",
    "    \"What are the test units for the hemoglobin A1c in my reports?\",\n",
    "    \"How many different types of reports have I had?\",\n",
    "    \"What was the highest payment I made for a single appointment and when?\",\n",
    "    \"What is the latest recommendation for my hypertension management?\",\n",
    "    \"What are the common recommendations for colds according?\",\n",
    "    \"What was the result of my Hemoglobin A1c in the last report?\",\n",
    "    \"What was the interpretation of my Hemoglobin A1c in the last report?\",\n",
    "    \"What was the interpretation of my bilirubin levels in the last report?\",\n",
    "    \"What are all the dates of all the appointments I've had with cardiologists?\",\n",
    "    \"How many times have I visited Cedars-Sinai for appointments?\",\n",
    "    \"What are the normal reference ranges for neutrophils?\",\n",
    "    \"What is the email of doctor Michael Smith?\",\n",
    "    \"What is the email of doctor Jane Doe?\",\n",
    "    \"What is the phone number of doctor John Doe?\",\n",
    "    \"What is the phone number of doctor Maria Garcia?\",\n",
    "    \"What hospital does Jane Doe work at?\",\n",
    "    \"What kind of doctor is Michael Smith?\",\n",
    "    \"What specialization is Maria Garcia?\",\n",
    "    \"What is the phone number of NYU Langone?\",\n",
    "    \"What is the address of Cedars-Sinai Medical Center?\",\n",
    "    \"How many hospitals do I have listed?\",\n",
    "    \"What units is the Cholesterol test in?\",\n",
    "    \"When is my next upcoming appointment?\",\n",
    "    \"Is there anything I should bring/prepare for my next appointment?\",\n",
    "    \"Where is my next appointment?\"\n",
    "\n",
    "]\n",
    "\n",
    "testset_2 = [\n",
    "    \"What was my hemoglobin level in the most recent report?\",\n",
    "    \"What medications am I currently prescribed, and what are their dosages?\",\n",
    "    \"Which hospital did I last visit for my medical visit?\",\n",
    "    \"What was the result of my last urine test?\",\n",
    "    \"What is the dosage and frequency of my Sitagliptin medicine?\",\n",
    "    \"What are the recommendations for managing my diabetes?\",\n",
    "    \"How many times a day should I take iron polysaccharide?\",\n",
    "    \"What is the phone number of the doctor at my family practice?\",\n",
    "    \"What is the phone number of Inova hospital?\",\n",
    "    \"What are the normal reference ranges for a glucose test and what were my levels?\",\n",
    "    \"Are there any test results I should be concerned about?\",\n",
    "    \"What was the interpretation of my last creatinine test result?\",\n",
    "    \"What are the tests for which I have a high interpretation?\",\n",
    "    \"When should I take my GLP1 shot?\",\n",
    "    \"What is my current dosage of metformin?\",\n",
    "    \"Do I need to adjust my medication based on any of my recent results?\",\n",
    "    \"What was my platelet count in the most recent blood report?\",\n",
    "    \"Based on my recent reports, how effective is my current treatment plan in managing my diabetes?\",\n",
    "    \"What is my hemoglobin A1c level, and what does that mean for my health?\",\n",
    "    \"How much did I pay for my medical appointments?\",\n",
    "    \"What is the dosage and frequency for the medicine Metformin that I am taking?\",\n",
    "    \"Can you provide a summary of my medical reports from the last month?\",\n",
    "    \"What are the test units for the hemoglobin A1c in my reports?\",\n",
    "    \"How many different types of reports have I had?\",\n",
    "    \"What was the result of my Hemoglobin A1c in the last report?\",\n",
    "    \"What was the interpretation of my Hemoglobin A1c in the last report?\",\n",
    "    \"What are all the dates of all the appointments I've had with my endocrinologist?\",\n",
    "    \"What is the address of the hospital in Virginia?\",\n",
    "    \"Where is Inova hospital?\",\n",
    "    \"How can I contact Virginia Hospital Center?\",\n",
    "    \"What are the addresses of all my hospitals?\",\n",
    "    \"What are the phone numbers of all my doctors?\",\n",
    "    \"Give me a summary of all my doctors.\",\n",
    "    \"List my personal information on hand.\",\n",
    "    \"Where was my first appointment this year?\",\n",
    "    \"What doctor did I see on April 24th?\",\n",
    "    \"How much have I paid for appointments this year?\",\n",
    "    \"How many medicines do I have to take every day?\",\n",
    "    \"What medicines do I have to take twice a day?\",\n",
    "    \"When and where is my next appointment?\",\n",
    "    \"What doctor will I see next?\",\n",
    "    \"What should I do if I need to cancel my next appointment?\",\n",
    "    \"I have a question about my Metformin medication, which doctor should I call?\",\n",
    "    \"Is my diabetes dangerous?\",\n",
    "    \"Are any of my medications dangerous?\",\n",
    "    \"Tell me one thing that is wrong with my dosages with my medication.\",\n",
    "    \"What is incorrect about the recommendations in my diagnoses?\",\n",
    "    \"How many remaining appointments do I have scheduled this year?\",\n",
    "    \"List my diagnoses\",\n",
    "    \"Is there anything I should bring/prepare for my next appointment?\",\n",
    "    \"Where is my last appointment?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Query Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['USER', 'appointments', 'diagnosis', 'diagnosis_by_doctor', 'doctor_specialization', 'doctors', 'hospitals', 'medicine', 'medicine_by_diagnosis', 'report_type', 'reports']\n",
      "['USER', 'appointments', 'diagnosis', 'diagnosis_by_doctor', 'doctor_specialization', 'doctors', 'hospitals', 'medicine', 'medicine_by_diagnosis', 'report_type', 'reports']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "import os\n",
    "from helper import generate_query, generate_response, SUBCHAIN_PROMPT, FULLCHAIN_PROMPT, RAG_CONTEXT\n",
    "from LLMs import OCTOAI_LLM_Chatbot, langdock_LLM_Chatbot\n",
    "from pathlib import Path\n",
    "import time\n",
    "import csv\n",
    "\n",
    "LANGDOCK_API_KEY = os.getenv(\"langdock_api_key\")\n",
    "LANGDOCK_BASE_URL = os.getenv(\"langdock_base_url\")\n",
    "OCTOAI_API_KEY = os.getenv(\"OCTOAI_TOKEN\")\n",
    "\n",
    "MODEL1 = \"meta-llama-3-8b-instruct\"\n",
    "# MODEL2 = \"gpt-4o\"\n",
    "\n",
    "llm_octo =OCTOAI_LLM_Chatbot(model_name=MODEL1, api_key=OCTOAI_API_KEY)\n",
    "\n",
    "\n",
    "# llm_langdock =langdock_LLM_Chatbot(model_name=MODEL2, api_key=LANGDOCK_API_KEY, base_url=LANGDOCK_BASE_URL) #instantiate anyscale llm object\n",
    "\n",
    "\n",
    "PMA_workspace = Path.cwd().parent.parent\n",
    "# print(PMA_workspace)\n",
    "db_path = PMA_workspace / \"desktop_app\" / \"ui\" / \"DB_query\" / \"med_assist.db\"\n",
    "\n",
    "\n",
    "# print(db_path)\n",
    "\n",
    "db_uri = f\"sqlite:////{db_path}\"\n",
    "\n",
    "DB = SQLDatabase.from_uri(db_uri)\n",
    "\n",
    "db2_path = PMA_workspace / \"desktop_app\" / \"ui\" / \"DB_query\" / \"drew.db\"\n",
    "\n",
    "db2_uri = f\"sqlite:////{db2_path}\"\n",
    "DB2 = SQLDatabase.from_uri(db2_uri)\n",
    "\n",
    "\n",
    "print(DB.get_usable_table_names())\n",
    "print(DB2.get_usable_table_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT first_name, last_name FROM USER'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_query(llm=llm_octo, template=SUBCHAIN_PROMPT, question=\"What is the user's name?\", db=DB2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meta llama3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for 60 seconds before processing the next set of questions...\n",
      "Waiting for 60 seconds before processing the next set of questions...\n",
      "Waiting for 60 seconds before processing the next set of questions...\n",
      "Waiting for 60 seconds before processing the next set of questions...\n",
      "Waiting for 60 seconds before processing the next set of questions...\n",
      "Waiting for 60 seconds before processing the next set of questions...\n",
      "Waiting for 60 seconds before processing the next set of questions...\n",
      "Waiting for 60 seconds before processing the next set of questions...\n",
      "Waiting for 60 seconds before processing the next set of questions...\n",
      "Waiting for 60 seconds before processing the next set of questions...\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "MODEL = \"meta-llama-3-8b-instruct\"\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Assuming sql_predictions_llama3 and testset_1 are already defined\n",
    "sql_predictions_llama3 = []\n",
    "\n",
    "for i in range(0, len(testset_1), 5):\n",
    "    for q in testset_1[i:i+5]:  # Process the next 5 questions\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "\n",
    "            query = generate_query(llm=llm_octo, template=SUBCHAIN_PROMPT, question=q, db=DB)\n",
    "            response = generate_response(llm=llm_octo, query=query, template=FULLCHAIN_PROMPT, question=q, db=DB)\n",
    "\n",
    "            query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "            response = response.replace(\"\\n\", \"\")\n",
    "\n",
    "            end_time = time.time()\n",
    "            execution_time = end_time - start_time\n",
    "\n",
    "            sql_predictions_llama3.append((response, query, execution_time))\n",
    "\n",
    "        except Exception as e:\n",
    "            query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "\n",
    "            sql_predictions_llama3.append((\"Error\", query))\n",
    "\n",
    "        # Write to CSV after each question\n",
    "        output_filename = f\"evaluation_files/{MODEL}_1.csv\"\n",
    "        with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows(sql_predictions_llama3)\n",
    "    \n",
    "    # Wait for 60 seconds after every 5 questions\n",
    "    if i + 5 < len(testset_1):  # Only wait if there are more questions to process\n",
    "        print(\"Waiting for 60 seconds before processing the next set of questions...\")\n",
    "        time.sleep(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_first_element_to_txt('evaluation_files/meta-llama-3-8b-instruct_1.csv', 'output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for 60 seconds before processing the next set of questions...\n",
      "Waiting for 60 seconds before processing the next set of questions...\n",
      "Waiting for 60 seconds before processing the next set of questions...\n",
      "Waiting for 60 seconds before processing the next set of questions...\n",
      "Waiting for 60 seconds before processing the next set of questions...\n",
      "Waiting for 60 seconds before processing the next set of questions...\n",
      "Waiting for 60 seconds before processing the next set of questions...\n",
      "Waiting for 60 seconds before processing the next set of questions...\n",
      "Waiting for 60 seconds before processing the next set of questions...\n",
      "Waiting for 60 seconds before processing the next set of questions...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MODEL = \"meta-llama-3-8b-instruct\"\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Assuming sql_predictions_llama3 and testset_1 are already defined\n",
    "sql_predictions_llama3 = []\n",
    "\n",
    "for i in range(0, len(testset_2), 5):\n",
    "    for q in testset_2[i:i+5]:  # Process the next 5 questions\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "\n",
    "            query = generate_query(llm=llm_octo, template=SUBCHAIN_PROMPT, question=q, db=DB2)\n",
    "            response = generate_response(llm=llm_octo, query=query, template=FULLCHAIN_PROMPT, question=q, db=DB2)\n",
    "\n",
    "            query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "            response = response.replace(\"\\n\", \"\")\n",
    "\n",
    "            end_time = time.time()\n",
    "            execution_time = end_time - start_time\n",
    "\n",
    "            sql_predictions_llama3.append((response, query, execution_time))\n",
    "\n",
    "        except Exception as e:\n",
    "            query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "\n",
    "            sql_predictions_llama3.append((\"Error\", query))\n",
    "\n",
    "        # Write to CSV after each question\n",
    "        output_filename = f\"evaluation_files/{MODEL}_2.csv\"\n",
    "        with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows(sql_predictions_llama3)\n",
    "    \n",
    "    # Wait for 60 seconds after every 5 questions\n",
    "    if i + 5 < len(testset_1):  # Only wait if there are more questions to process\n",
    "        print(\"Waiting for 60 seconds before processing the next set of questions...\")\n",
    "        time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_first_element_to_txt('evaluation_files/meta-llama-3-8b-instruct_2.csv', 'output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMs import MISTRAL_LLM_Chatbot\n",
    "\n",
    "MODEL = \"open-mistral-7b\"\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "\n",
    "mistral = MISTRAL_LLM_Chatbot(model_name=MODEL,api_key=MISTRAL_API_KEY)\n",
    "\n",
    "query = generate_query(llm=mistral, template=SUBCHAIN_PROMPT, question=\"what is the user's name?\", db=DB2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mistral open 7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     11\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 13\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmistral\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSUBCHAIN_PROMPT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     16\u001b[0m     response \u001b[38;5;241m=\u001b[39m generate_response(llm\u001b[38;5;241m=\u001b[39mmistral, query\u001b[38;5;241m=\u001b[39mquery, template\u001b[38;5;241m=\u001b[39mFULLCHAIN_PROMPT, question\u001b[38;5;241m=\u001b[39mq, db\u001b[38;5;241m=\u001b[39mDB)\n",
      "File \u001b[0;32m~/LLM/Personal-Medical-Assistant/backend/full_chain/helper.py:139\u001b[0m, in \u001b[0;36mgenerate_query\u001b[0;34m(llm, template, question, db)\u001b[0m\n\u001b[1;32m    137\u001b[0m current_time \u001b[38;5;241m=\u001b[39m get_current_time()\n\u001b[1;32m    138\u001b[0m prompt \u001b[38;5;241m=\u001b[39m template\u001b[38;5;241m.\u001b[39mformat(schema\u001b[38;5;241m=\u001b[39mget_schema(db),question\u001b[38;5;241m=\u001b[39mquestion, current_date\u001b[38;5;241m=\u001b[39mcurrent_time)       \u001b[38;5;66;03m#format template to include all necessary information (schema, question)\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m sql_query \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m         \u001b[38;5;66;03m#generates sql query\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sql_query\n",
      "File \u001b[0;32m~/LLM/Personal-Medical-Assistant/backend/full_chain/LLMs.py:152\u001b[0m, in \u001b[0;36mMISTRAL_LLM_Chatbot.chat_completion\u001b[0;34m(self, prompt, question)\u001b[0m\n\u001b[1;32m    146\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    147\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt},\n\u001b[1;32m    148\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: question}\n\u001b[1;32m    149\u001b[0m ]\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     content \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    159\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI Response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/mistralai/chat.py:106\u001b[0m, in \u001b[0;36mChat.complete\u001b[0;34m(self, model, messages, temperature, top_p, max_tokens, min_tokens, stream, stop, random_seed, response_format, tools, tool_choice, safe_prompt, retries, server_url, timeout_ms)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(retries, utils\u001b[38;5;241m.\u001b[39mRetryConfig):\n\u001b[1;32m     98\u001b[0m     retry_config \u001b[38;5;241m=\u001b[39m (retries, [\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m429\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m500\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m504\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m     ])                \n\u001b[0;32m--> 106\u001b[0m http_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhook_ctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHookContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchat_completion_v1_chat_completions_post\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moauth2_scopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecurity_source\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_security_from_env\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msdk_configuration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msecurity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSecurity\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_status_codes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m422\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m4XX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m5XX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_config\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m data: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mmatch_response(http_res, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m200\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/mistralai/basesdk.py:173\u001b[0m, in \u001b[0;36mBaseSDK.do_request\u001b[0;34m(self, hook_ctx, request, error_status_codes, stream, retry_config)\u001b[0m\n\u001b[1;32m    171\u001b[0m     http_res \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mretry(do, utils\u001b[38;5;241m.\u001b[39mRetries(retry_config[\u001b[38;5;241m0\u001b[39m], retry_config[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     http_res \u001b[38;5;241m=\u001b[39m \u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mmatch_status_codes(error_status_codes, http_res\u001b[38;5;241m.\u001b[39mstatus_code):\n\u001b[1;32m    176\u001b[0m     http_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msdk_configuration\u001b[38;5;241m.\u001b[39mget_hooks()\u001b[38;5;241m.\u001b[39mafter_success(\n\u001b[1;32m    177\u001b[0m         AfterSuccessContext(hook_ctx), http_res\n\u001b[1;32m    178\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/mistralai/basesdk.py:134\u001b[0m, in \u001b[0;36mBaseSDK.do_request.<locals>.do\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m     req \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msdk_configuration\u001b[38;5;241m.\u001b[39mget_hooks()\u001b[38;5;241m.\u001b[39mbefore_request(\n\u001b[1;32m    125\u001b[0m         BeforeRequestContext(hook_ctx), request\n\u001b[1;32m    126\u001b[0m     )\n\u001b[1;32m    127\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMethod: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mURL: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mHeaders: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBody: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    129\u001b[0m         req\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m         get_body_content(req)\n\u001b[1;32m    133\u001b[0m     )\n\u001b[0;32m--> 134\u001b[0m     http_res \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    136\u001b[0m     _, e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msdk_configuration\u001b[38;5;241m.\u001b[39mget_hooks()\u001b[38;5;241m.\u001b[39mafter_error(\n\u001b[1;32m    137\u001b[0m         AfterErrorContext(hook_ctx), \u001b[38;5;28;01mNone\u001b[39;00m, e\n\u001b[1;32m    138\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[1;32m    910\u001b[0m )\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1012\u001b[0m     )\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    238\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    239\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    240\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    241\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    242\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/ssl.py:1292\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1290\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1291\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/ssl.py:1165\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from LLMs import MISTRAL_LLM_Chatbot\n",
    "\n",
    "MODEL = \"open-mistral-7b\"\n",
    "mistral = MISTRAL_LLM_Chatbot(model_name=MODEL,api_key=MISTRAL_API_KEY)\n",
    "\n",
    "sql_predictions = []\n",
    "\n",
    "for q in testset_1:\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "\n",
    "        query = generate_query(llm=mistral, template=SUBCHAIN_PROMPT, question=q, db=DB)\n",
    "        time.sleep(5)\n",
    "\n",
    "        response = generate_response(llm=mistral, query=query, template=FULLCHAIN_PROMPT, question=q, db=DB)\n",
    "\n",
    "        query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "        response = response.replace(\"\\n\", \"\")\n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        sql_predictions.append((response, query, execution_time))\n",
    "\n",
    "    except Exception as e:\n",
    "        query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "\n",
    "        sql_predictions.append((\"Error\", query))\n",
    "\n",
    "    # time.sleep(30)\n",
    "    time.sleep(5)\n",
    "\n",
    "    output_filename = f\"evaluation_files/{MODEL}_1.csv\"\n",
    "    with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write each tuple in the list to the CSV file\n",
    "            writer.writerows(sql_predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testset 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) no such table: users\n[SQL: SELECT a.appointment_date\nFROM appointments AS a\nJOIN users AS u ON a.user_id = u.user_id\nWHERE u.user_id = (SELECT user_id FROM USER WHERE first_name = 'Belen' AND last_name = 'Tavares')\nAND a.appointment_date > CURDATE()\nORDER BY a.appointment_date ASC\nLIMIT 1;]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1967\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/sqlalchemy/engine/default.py:941\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 941\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: users",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m generate_query(llm\u001b[38;5;241m=\u001b[39mmistral, template\u001b[38;5;241m=\u001b[39mSUBCHAIN_PROMPT, question\u001b[38;5;241m=\u001b[39mtestset_1[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], db\u001b[38;5;241m=\u001b[39mDB)\n\u001b[1;32m      2\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmistral\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFULLCHAIN_PROMPT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDB\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LLM/Personal-Medical-Assistant/backend/full_chain/helper.py:159\u001b[0m, in \u001b[0;36mgenerate_response\u001b[0;34m(llm, query, template, question, db)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_response\u001b[39m(llm, query, template, question, db):\n\u001b[1;32m    145\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03m    Generates an SQL query.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    response (str): Natural language response to user's question\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m     executed_query \u001b[38;5;241m=\u001b[39m \u001b[43mrun_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb\u001b[49m\u001b[43m)\u001b[49m    \u001b[38;5;66;03m#execute query on database\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# print(f\"\\nExecuted query: {executed_query}\\n\")\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     formatted_template \u001b[38;5;241m=\u001b[39m template\u001b[38;5;241m.\u001b[39mformat(question\u001b[38;5;241m=\u001b[39mquestion, query\u001b[38;5;241m=\u001b[39mquery, executed_query\u001b[38;5;241m=\u001b[39mexecuted_query)     \u001b[38;5;66;03m#format template to include new information\u001b[39;00m\n",
      "File \u001b[0;32m~/LLM/Personal-Medical-Assistant/backend/full_chain/helper.py:121\u001b[0m, in \u001b[0;36mrun_query\u001b[0;34m(query, db)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_query\u001b[39m(query, db):\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    Takes query and runs query in database (db)\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/langchain_community/utilities/sql_database.py:502\u001b[0m, in \u001b[0;36mSQLDatabase.run\u001b[0;34m(self, command, fetch, include_columns, parameters, execution_options)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    490\u001b[0m     command: Union[\u001b[38;5;28mstr\u001b[39m, Executable],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    495\u001b[0m     execution_options: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    496\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[\u001b[38;5;28mstr\u001b[39m, Sequence[Dict[\u001b[38;5;28mstr\u001b[39m, Any]], Result[Any]]:\n\u001b[1;32m    497\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Execute a SQL command and return a string representing the results.\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \n\u001b[1;32m    499\u001b[0m \u001b[38;5;124;03m    If the statement returns rows, a string of the results is returned.\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;124;03m    If the statement returns no rows, an empty string is returned.\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 502\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_options\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fetch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcursor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/langchain_community/utilities/sql_database.py:467\u001b[0m, in \u001b[0;36mSQLDatabase._execute\u001b[0;34m(self, command, fetch, parameters, execution_options)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery expression has unknown type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(command)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 467\u001b[0m cursor \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mreturns_rows:\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fetch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1418\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1419\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/sqlalchemy/sql/elements.py:515\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1640\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[1;32m   1628\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1629\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[1;32m   1630\u001b[0m )\n\u001b[1;32m   1632\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1633\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[1;32m   1634\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1638\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1639\u001b[0m )\n\u001b[0;32m-> 1640\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[1;32m   1654\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1655\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1659\u001b[0m         ret,\n\u001b[1;32m   1660\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1846\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_insertmany_context(dialect, context)\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1986\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1983\u001b[0m     result \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39m_setup_result_proxy()\n\u001b[1;32m   1985\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1986\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1987\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1988\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/sqlalchemy/engine/base.py:2355\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[1;32m   2353\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[1;32m   2354\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   2356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2357\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/sqlalchemy/engine/base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1965\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1967\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[1;32m   1972\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1973\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1974\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1978\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[1;32m   1979\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/LLM/lib/python3.10/site-packages/sqlalchemy/engine/default.py:941\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 941\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOperationalError\u001b[0m: (sqlite3.OperationalError) no such table: users\n[SQL: SELECT a.appointment_date\nFROM appointments AS a\nJOIN users AS u ON a.user_id = u.user_id\nWHERE u.user_id = (SELECT user_id FROM USER WHERE first_name = 'Belen' AND last_name = 'Tavares')\nAND a.appointment_date > CURDATE()\nORDER BY a.appointment_date ASC\nLIMIT 1;]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "query = generate_query(llm=mistral, template=SUBCHAIN_PROMPT, question=testset_1[-1], db=DB)\n",
    "time.sleep(5)\n",
    "response = generate_response(llm=mistral, query=query, template=FULLCHAIN_PROMPT, question=q, db=DB)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_first_element_to_txt('evaluation_files/open-mistral-7b_1.csv',\"output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can only execute one statement at a time.\n",
      "(sqlite3.OperationalError) no such column: m.medicine_name\n",
      "[SQL: SELECT m.medicine_name, m.dosage, m.units\n",
      "FROM medicine_by_diagnosis mbd\n",
      "JOIN diagnosis_by_doctor dbd ON mbd.diagnosis_id = dbd.diagnosis_id\n",
      "JOIN doctors d ON dbd.doctor_id = d.doctor_id\n",
      "JOIN appointments a ON d.doctor_id = a.doctor_id\n",
      "JOIN user u ON a.user_id = u.user_id\n",
      "WHERE u.user_id = (SELECT user_id FROM user WHERE first_name = 'Drew' AND last_name = 'Smith')\n",
      "AND a.appointment_date <= '2024-01-09';]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such table: users\n",
      "[SQL: SELECT hospitals.hospital_name\n",
      "FROM appointments\n",
      "JOIN users ON appointments.user_id = users.user_id\n",
      "JOIN hospitals ON appointments.hospital_id = hospitals.hospital_id\n",
      "WHERE users.user_id = (SELECT user_id FROM appointments WHERE appointment_date = (SELECT MAX(appointment_date) FROM appointments WHERE user_id = (SELECT user_id FROM users WHERE first_name = 'Drew' AND last_name = 'Smith')))\n",
      "LIMIT 1;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) near \"FETCH\": syntax error\n",
      "[SQL: SELECT test_result, test_units, test_reference_range, interpretation\n",
      "FROM reports\n",
      "WHERE user_id = (SELECT user_id FROM USER WHERE first_name = SUBSTRING(FIRST_NAME(SYSDATE), 1, 1) || SUBSTRING(FIRST_NAME(SYSDATE), 2, 1) || SUBSTRING(FIRST_NAME(SYSDATE), 3, 1) || SUBSTRING(LAST_NAME(SYSDATE), 1, 1) || SUBSTRING(LAST_NAME(SYSDATE), 2, 1) || SUBSTRING(LAST_NAME(SYSDATE), 3, 1) ORDER BY ROWNUM DESC FETCH NEXT 1 ROWS ONLY).\n",
      "AND test_name = 'Urine Microalbumin'\n",
      "ORDER BY report_date DESC\n",
      "LIMIT 1;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: doctors.first_name\n",
      "[SQL: SELECT medicine.dosage, medicine.daily_frequency FROM medicine\n",
      "JOIN medicine_by_diagnosis ON medicine.medicine_id = medicine_by_diagnosis.medicine_id\n",
      "JOIN diagnosis_by_doctor ON diagnosis_by_doctor.diagnosis_id = diagnosis.diagnosis_id\n",
      "JOIN diagnosis ON diagnosis_by_doctor.doctor_id = doctors.doctor_id\n",
      "WHERE doctors.first_name = 'Your First Name' AND doctors.last_name = 'Your Last Name' AND medicine.medicine_name = 'Sitagliptin';\n",
      "\n",
      "Please replace 'Your First Name' and 'Your Last Name' with the actual first and last names of the user. This SQL query will return the dosage and frequency of Sitagliptin medicine for the specified user.]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such table: diagnosis_by_medicine\n",
      "[SQL: SELECT d.diagnosis_name, dbd.recommendations\n",
      "FROM diagnosis d\n",
      "JOIN diagnosis_by_doctor dbd ON d.diagnosis_id = dbd.diagnosis_id\n",
      "JOIN diagnosis_by_medicine dbm ON d.diagnosis_id = dbm.diagnosis_id\n",
      "JOIN medicine_by_diagnosis mbd ON dbm.medicine_id = mbd.medicine_id\n",
      "WHERE d.diagnosis_name = 'Diabetes Type 2'\n",
      "AND EXISTS (SELECT 1 FROM appointments a WHERE a.user_id = (SELECT user_id FROM USER WHERE first_name = 'Drew' AND last_name = 'Smith') AND a.appointment_date <= CURDATE())\n",
      "AND EXISTS (SELECT 1 FROM reports r WHERE r.user_id = (SELECT user_id FROM USER WHERE first_name = 'Drew' AND last_name = 'Smith') AND r.report_date <= CURDATE());]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) near \"To\": syntax error\n",
      "[SQL: To answer this question, we first need to find the medicine with the name \"iron polysaccharide\" and its dosage frequency. Since the medicine table does not have a name column, we'll need to join it with the `medicine_by_diagnosis` table using the `diagnosis` table as an intermediary. The `diagnosis` table is not directly related to the user's medication, so we cannot directly retrieve this information.\n",
      "\n",
      "However, assuming you have a diagnosis or a prescription with the correct medicine information, you can use the following query to retrieve the dosage frequency:\n",
      "\n",
      "```sql\n",
      "SELECT medicine_daily_frequency\n",
      "FROM medicine\n",
      "JOIN medicine_by_diagnosis ON medicine.medicine_id = medicine_by_diagnosis.medicine_id\n",
      "WHERE medicine_name = 'iron polysaccharide';\n",
      "```\n",
      "\n",
      "This query will return the number of times you should take iron polysaccharide per day. If you don't have a diagnosis or prescription, you need to consult your doctor or healthcare provider for this information.]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "You can only execute one statement at a time.\n",
      "(sqlite3.OperationalError) no such column: r.test_reference_range_lower\n",
      "[SQL: SELECT r.report_date, t.report_type_name, r.test_name, r.test_result, r.test_reference_range, CASE WHEN r.test_result < r.test_reference_range_lower OR r.test_result > r.test_reference_range_upper THEN 'Yes' ELSE 'No' END as concern\n",
      "FROM reports r\n",
      "JOIN report_type t ON r.report_type_id = t.report_type_id\n",
      "WHERE r.user_id = (SELECT user_id FROM USER WHERE first_name = 'Drew' AND last_name = 'Smith')\n",
      "AND r.report_date <= '2024-01-09';]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such function: SUBSTRING_INDEX\n",
      "[SQL: SELECT interpretation FROM reports WHERE user_id = (SELECT user_id FROM USER WHERE first_name = SUBSTRING_INDEX(REPLACE(LOWER('Drew Smith'), ' ', ''), ' ', -1) AND last_name = SUBSTRING_INDEX(REPLACE(LOWER('Smith'), ' ', ''), ' ', -1)) AND test_name = 'Creatinine' AND report_date = (SELECT MAX(report_date) FROM reports WHERE user_id = (SELECT user_id FROM USER WHERE first_name = SUBSTRING_INDEX(REPLACE(LOWER('Drew Smith'), ' ', ''), ' ', -1) AND last_name = SUBSTRING_INDEX(REPLACE(LOWER('Smith'), ' ', ''), ' ', -1))) ;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "You can only execute one statement at a time.\n",
      "(sqlite3.OperationalError) no such column: diagnosis.diagnosis_id\n",
      "[SQL: SELECT medicine.dosage\n",
      "FROM medicine\n",
      "JOIN medicine_by_diagnosis ON medicine.medicine_id = medicine_by_diagnosis.medicine_id\n",
      "JOIN diagnosis_by_doctor ON diagnosis_by_doctor.diagnosis_id = diagnosis.diagnosis_id\n",
      "JOIN doctors ON doctors.doctor_id = diagnosis_by_doctor.doctor_id\n",
      "JOIN appointments ON appointments.doctor_id = doctors.doctor_id\n",
      "JOIN user ON appointments.user_id = user.user_id\n",
      "WHERE user.user_id = (SELECT user_id FROM appointments WHERE appointments.appointment_date = '2024-01-18' OR appointments.appointment_date = '2024-04-24') -- replace with the actual user's appointment dates\n",
      "AND medicine_by_diagnosis.diagnosis_id = diagnosis.diagnosis_id\n",
      "AND diagnosis.diagnosis_name = 'Diabetes Type 2' -- replace with the actual diagnosis\n",
      "AND doctors.last_name = 'Jackson' OR doctors.last_name = 'Hernandez' OR doctors.last_name = 'Martin' -- replace with the actual doctor's last name\n",
      "AND appointments.appointment_date <= '2024-01-09' -- replace with the current date\n",
      "LIMIT 1;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such table: diagnoses\n",
      "[SQL: SELECT DISTINCT r.user_id, d.diagnosis_name, m.medicine_name, r.report_date, r.test_result\n",
      "FROM reports r\n",
      "JOIN diagnoses d ON r.diagnosis_id = d.diagnosis_id\n",
      "JOIN medicine_by_diagnosis mb ON d.diagnosis_id = mb.diagnosis_id\n",
      "JOIN medicine m ON mb.medicine_id = m.medicine_id\n",
      "WHERE r.user_id = (SELECT user_id FROM USER WHERE first_name = 'Drew' AND last_name = 'Smith')\n",
      "AND r.report_date >= '2024-01-01' AND r.report_date <= CURDATE()\n",
      "AND r.test_result NOT IN (SELECT test_reference_range FROM reports WHERE user_id = (SELECT user_id FROM USER WHERE first_name = 'Drew' AND last_name = 'Smith'))\n",
      "ORDER BY r.report_date DESC;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: USER\n",
      "[SQL: SELECT test_result FROM reports WHERE user_id = (SELECT user_id FROM USER WHERE first_name = SUBSTRING(FIRST_NAME(USER), 1, 1) AND last_name = SUBSTRING(LAST_NAME(USER), 1, 1) AND YEAR(birth_date) = YEAR(CURRENT_DATE) - YEAR(STR_TO_DATE('01/09/2024', '%d/%m/%Y'))) AND test_name = 'Platelet count' AND report_type_id = (SELECT report_type_id FROM report_type WHERE report_type_name = 'Blood report') ORDER BY report_date DESC LIMIT 1;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such function: GETDATE\n",
      "[SQL: SELECT AVG(reports.test_result) AS Average_Blood_Glucose,\n",
      "       COUNT(DISTINCT reports.report_id) AS Number_Of_Reports\n",
      "FROM reports\n",
      "JOIN medicine_by_diagnosis ON reports.report_id = medicine_by_diagnosis.report_id\n",
      "JOIN diagnosis ON medicine_by_diagnosis.diagnosis_id = diagnosis.diagnosis_id\n",
      "JOIN diagnosis_by_doctor ON diagnosis.diagnosis_id = diagnosis_by_doctor.diagnosis_id\n",
      "JOIN doctors ON diagnosis_by_doctor.doctor_id = doctors.doctor_id\n",
      "JOIN appointments ON doctors.doctor_id = appointments.doctor_id\n",
      "JOIN USER ON appointments.user_id = USER.user_id\n",
      "WHERE USER.first_name = '<Your_First_Name>' AND USER.last_name = '<Your_Last_Name>' AND diagnosis.diagnosis_name = 'Diabetes Type 2' AND reports.report_type_id IN (1) -- Replace (1) with the appropriate report_type_id for blood glucose tests\n",
      "AND reports.report_date BETWEEN DATEADD(month, -6, GETDATE()) AND GETDATE() -- Adjust the time frame as needed\n",
      "GROUP BY reports.report_id;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: doctors.first_name\n",
      "[SQL: SELECT medicine.dosage, medicine.daily_frequency FROM medicine\n",
      "JOIN medicine_by_diagnosis ON medicine.medicine_id = medicine_by_diagnosis.medicine_id\n",
      "JOIN diagnosis_by_doctor ON diagnosis_by_doctor.diagnosis_id = diagnosis.diagnosis_id\n",
      "JOIN diagnosis ON diagnosis_by_doctor.doctor_id = doctors.doctor_id\n",
      "JOIN appointments ON appointments.user_id = USER.user_id\n",
      "WHERE medicine.medicine_name = 'Metformin' AND doctors.first_name = (SELECT first_name FROM USER WHERE user_id = appointments.user_id);]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) near \"'1 month'\": syntax error\n",
      "[SQL: SELECT DATE_TRUNC('month', r.report_date) AS ReportMonth,\n",
      "       r.test_name,\n",
      "       r.test_result,\n",
      "       r.test_units,\n",
      "       r.test_reference_range,\n",
      "       r.interpretation\n",
      "FROM reports r\n",
      "WHERE r.user_id = 1 AND\n",
      "      r.report_date >= DATE_TRUNC('month', CURRENT_DATE) - INTERVAL '1 month';]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) near \"<\": syntax error\n",
      "[SQL: SELECT DISTINCT report_type_id FROM reports WHERE user_id = (SELECT user_id FROM USER WHERE first_name = <YourFirstName> AND last_name = <YourLastName>);]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: doctors.user_id\n",
      "[SQL: SELECT appointment_date FROM appointments WHERE user_id = (SELECT user_id FROM USER JOIN doctors ON USER.user_id = doctors.user_id WHERE doctors.specialization_id = (SELECT specialization_id FROM doctor_specialization WHERE specialization_name = 'Endocrinologist')) AND doctor_id = (SELECT doctor_id FROM doctors WHERE first_name = SUBSTRING(first_name, 1, 1) || SUBSTRING(last_name, 1, 1) || SUBSTRING(last_name, LEN(last_name) - 1, 1) ORDER BY LEN(last_name) DESC, LEN(last_name) = LEN(first_name) DESC, last_name <> first_name DESC LIMIT 1);]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such function: YEAR\n",
      "[SQL: SELECT SUM(payment_total)\n",
      "FROM appointments\n",
      "WHERE YEAR(appointment_date) = YEAR(CURRENT_DATE);]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: daily_frequency\n",
      "[SQL: SELECT SUM(daily_frequency) as total_daily_doses\n",
      "FROM medicine_by_diagnosis\n",
      "JOIN diagnosis ON medicine_by_diagnosis.diagnosis_id = diagnosis.diagnosis_id\n",
      "JOIN diagnosis_by_doctor ON diagnosis.diagnosis_id = diagnosis_by_doctor.diagnosis_id\n",
      "JOIN doctors ON diagnosis_by_doctor.doctor_id = doctors.doctor_id\n",
      "JOIN appointments ON doctors.doctor_id = appointments.doctor_id\n",
      "JOIN user ON appointments.user_id = user.user_id\n",
      "WHERE user.user_id = (SELECT user_id FROM user WHERE first_name = 'Drew' AND last_name = 'Smith')\n",
      "AND appointments.appointment_date <= '2024-01-09';]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such function: CURDATE\n",
      "[SQL: SELECT a.appointment_date, h.hospital_name\n",
      "FROM appointments AS a\n",
      "JOIN hospitals AS h ON a.hospital_id = h.hospital_id\n",
      "WHERE a.user_id = 1 AND a.appointment_date > CURDATE()\n",
      "ORDER BY a.appointment_date ASC\n",
      "LIMIT 1;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such function: CURDATE\n",
      "[SQL: SELECT d.first_name, d.last_name\n",
      "FROM appointments a\n",
      "JOIN doctors d ON a.doctor_id = d.doctor_id\n",
      "JOIN appointments AS next_appointment ON d.doctor_id = next_appointment.doctor_id\n",
      "WHERE a.user_id = 1 AND a.appointment_date < CURDATE() AND next_appointment.appointment_date >= CURDATE()\n",
      "ORDER BY next_appointment.appointment_date ASC\n",
      "LIMIT 1;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) near \"To\": syntax error\n",
      "[SQL: To find the user's next appointment and provide the necessary SQL command to cancel it, first, let's find the user's next appointment date. Then, we can provide a SQL command to update the appointments table to cancel the appointment.\n",
      "\n",
      "Here's the SQL query to find the user's next appointment date:\n",
      "\n",
      "```sql\n",
      "SELECT MIN(appointment_date) as next_appointment_date\n",
      "FROM appointments\n",
      "WHERE user_id = 1 AND appointment_date > '2024-01-09';\n",
      "```\n",
      "\n",
      "Now let's create a SQL command to cancel the appointment by setting its status to 'Cancelled'.\n",
      "\n",
      "```sql\n",
      "UPDATE appointments\n",
      "SET status = 'Cancelled'\n",
      "WHERE user_id = 1 AND appointment_date = (SELECT MIN(appointment_date) as next_appointment_date FROM appointments WHERE user_id = 1 AND appointment_date > '2024-01-09');\n",
      "```\n",
      "\n",
      "Please note that the 'status' column is not provided in the schema, so you might need to add this column to the appointments table with a default value of 'Scheduled' or similar before running this command.\n",
      "\n",
      "The first SQL query finds the next appointment date for user_id 1, and the second SQL query cancels this appointment.]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: h.hospital_id\n",
      "[SQL: SELECT d.first_name, d.last_name, d.phone_number\n",
      "FROM doctors d\n",
      "JOIN medicine_by_diagnosis mbd ON d.doctor_id = mbd.doctor_id\n",
      "JOIN diagnosis dg ON mbd.diagnosis_id = dg.diagnosis_id\n",
      "JOIN medicine m ON m.medicine_id = mbd.medicine_id\n",
      "WHERE m.medicine_name = 'Metformin' AND d.hospital_id IN (\n",
      "    SELECT h.hospital_id\n",
      "    FROM appointments a\n",
      "    JOIN USER u ON a.user_id = u.user_id\n",
      "    WHERE u.first_name = 'Drew' AND u.last_name = 'Smith'\n",
      ")\n",
      "ORDER BY d.last_name;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) near \"To\": syntax error\n",
      "[SQL: To answer the user's question about the severity of their diabetes, we need to analyze their blood glucose levels and compare them to the normal range. We can use the `reports` table to find the user's blood glucose levels and the `diagnosis` table to confirm that the user has diabetes.\n",
      "\n",
      "Here's the SQL query that satisfies the given conditions:\n",
      "\n",
      "```sql\n",
      "SELECT CASE\n",
      "        WHEN AVG(reports.test_result) < 130 THEN 'Your diabetes is under control.'\n",
      "        WHEN AVG(reports.test_result) BETWEEN 130 AND 170 THEN 'Your diabetes is managed but requires closer monitoring.'\n",
      "        ELSE 'Your diabetes is not well-controlled and may be dangerous.'\n",
      "    END AS diabetes_status\n",
      "FROM reports\n",
      "JOIN user ON reports.user_id = user.user_id\n",
      "WHERE user.first_name = 'Drew' AND user.last_name = 'Smith' AND reports.test_name = 'Hemoglobin A1c' AND reports.test_type_id = 1 AND reports.report_date >= '2023-01-01' AND reports.report_date <= CURDATE();\n",
      "```\n",
      "\n",
      "This query calculates the average Hemoglobin A1c level for the user Drew Smith over a specific date range (from January 1st, 2023, to the current date) and classifies the diabetes status based on the average results.]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such table: dosage_recommendations\n",
      "[SQL: SELECT m.medicine_name, m.dosage, (m.dosage * m.daily_frequency) AS total_dosage, d.recommendations\n",
      "FROM medicine m\n",
      "JOIN medicine_by_diagnosis mb ON m.medicine_id = mb.medicine_id\n",
      "JOIN diagnosis d ON mb.diagnosis_id = d.diagnosis_id\n",
      "JOIN appointments a ON a.user_id = (SELECT user_id FROM USER WHERE first_name = 'Drew' AND last_name = 'Smith')\n",
      "WHERE a.appointment_date <= DATE(CURRENT_DATE)\n",
      "AND m.dosage * m.daily_frequency > (SELECT recommendation_value FROM dosage_recommendations WHERE recommendation_name = d.recommendations)\n",
      "LIMIT 1;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such table: Dosage_Guidelines\n",
      "[SQL: SELECT d.diagnosis_name, REPLACE(d.recommendations, INcorrect_part, Correct_part) AS Corrected_recommendations\n",
      "FROM diagnosis d\n",
      "JOIN diagnosis_by_doctor dbd ON d.diagnosis_id = dbd.diagnosis_id\n",
      "JOIN doctors dct ON dbd.doctor_id = dct.doctor_id\n",
      "WHERE dct.email = 'your_email@example.com' -- Replace 'your_email@example.com' with the actual email of the user\n",
      "AND dct.hospital_id IN (SELECT hospital_id FROM hospitals) -- Replace this subquery with the actual hospital IDs if necessary\n",
      "AND STRFTIME('%Y-%m', d.diagnosis_date) <= STRFTIME('%Y-%m', '2024-01-09') -- This condition filters diagnoses that are within the last 3 months\n",
      "AND NOT EXISTS (\n",
      "    SELECT 1\n",
      "    FROM Medicine m\n",
      "    JOIN medicine_by_diagnosis mbd ON m.medicine_id = mbd.medicine_id\n",
      "    WHERE mbd.diagnosis_id = d.diagnosis_id\n",
      "    AND m.dosage NOT IN (SELECT dosage FROM Dosage_Guidelines WHERE diagnosis_id = d.diagnosis_id) -- Replace this subquery with the actual dosage guidelines for each diagnosis\n",
      ") -- This condition checks if the recommended dosage for each medicine is within the guidelines\n",
      "AND NOT EXISTS (\n",
      "    SELECT 1\n",
      "    FROM Nutrient_Guidelines ng\n",
      "    WHERE ng.diagnosis_id = d.diagnosis_id\n",
      "    AND NOT EXISTS (\n",
      "        SELECT 1\n",
      "        FROM Foods f\n",
      "        WHERE f.food_name IN (\n",
      "            SEPARATE_STRING(d.recommendations, ' ', ',') -- This function separates the recommendations into individual food names\n",
      "        )\n",
      "        AND f.nutrient_id IN (\n",
      "            SELECT nutrient_id FROM Nutrients WHERE food_id = f.food_id\n",
      "        )\n",
      "        AND f.nutrient_value < ng.lower_bound -- This condition checks if the nutrient value of each food is within the guidelines\n",
      "        OR f.nutrient_value > ng.upper_bound -- This condition checks if the nutrient value of each food is within the guidelines\n",
      "    )\n",
      ") -- This condition checks if the nutrient value of each food in the recommendations is within the guidelines\n",
      "AND EXISTS ( -- This condition checks if there are any incorrect parts in the recommendations\n",
      "    SELECT 1\n",
      "    FROM (\n",
      "        SELECT\n",
      "            SUBSTRING_INDEX(d.recommendations, ' ', NUMBER_OF_EXTRACTS(d.recommendations, ' ')) AS recommendation_part,\n",
      "            COUNT(*) OVER () AS total_parts\n",
      "        FROM diagnosis d\n",
      "        JOIN diagnosis_by_doctor dbd ON d.diagnosis_id = dbd.diagnosis_id\n",
      "        JOIN doctors dct ON dbd.doctor_id = dct.doctor_id\n",
      "        WHERE dct.email = 'your_email@example.com' -- Replace 'your_email@example.com' with the actual email of the user\n",
      "        AND dct.hospital_id IN (SELECT hospital_id FROM hospitals) -- Replace this subquery with the actual hospital IDs if necessary\n",
      "        AND STRFTIME('%Y-%m', d.diagnosis_date) <= STRFTIME('%Y-%m', '2024-01-09') -- This condition filters diagnoses that are within the last 3 months\n",
      "    ) t\n",
      "    WHERE t.total_parts > 1\n",
      "    AND NOT EXISTS (\n",
      "        SELECT 1\n",
      "        FROM (\n",
      "            SELECT\n",
      "                SUBSTRING_INDEX(d.recommendations, ' ', NUMBER_OF_EXTRACTS(d.recommendations, ' ')) AS recommendation_part,\n",
      "                COUNT(*) OVER () AS total_parts\n",
      "            FROM diagnosis d\n",
      "            JOIN diagnosis_by_doctor dbd ON d.diagnosis_id = dbd.diagnosis_id\n",
      "            JOIN doctors dct ON dbd.doctor_id = dct.doctor_id\n",
      "            WHERE dct.email = 'your_email@example.com' -- Replace 'your_email@example.com' with the actual email of the user\n",
      "            AND dct.hospital_id IN (SELECT hospital_id FROM hospitals) -- Replace this subquery with the actual hospital IDs if necessary\n",
      "            AND STRFTIME('%Y-%m', d.diagnosis_date) <= STRFTIME('%Y-%m', '2024-01-09') -- This condition filters diagnoses that are within the last 3 months\n",
      "            AND SUBSTRING_INDEX(d.recommendations, ' ', NUMBER_OF_EXTRACTS(d.recommendations, ' ')) = t.recommendation_part\n",
      "        ) c\n",
      "        WHERE c.total_parts = 1\n",
      "    )\n",
      ")\n",
      "GROUP BY d.diagnosis_name\n",
      "HAVING COUNT(*) > 0\n",
      "ORDER BY COUNT(*) DESC;\n",
      "\n",
      "This query checks the recommendations in the diagnoses for incorrect parts and returns the diagnosis name and the corrected recommendations. The query filters the diagnoses based on the user's email (or hospital ID if necessary), the diagnosis date, and the dosage guidelines for each medicine. It also checks if the nutrient value of each food in the recommendations is within the guidelines. The query returns the diagnosis name and the corrected recommendations for any diagnoses with incorrect parts in the recommendations.]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) near \"FROM\": syntax error\n",
      "[SQL: SELECT COUNT(a.appointment_id)\n",
      "FROM appointments a\n",
      "WHERE EXTRACT(YEAR FROM a.appointment_date) = EXTRACT(YEAR FROM '2024-01-01')\n",
      "AND a.appointment_date < DATEADD(year, 1, CAST(GETDATE() AS date));]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such function: CURDATE\n",
      "[SQL: SELECT d.recommendations\n",
      "FROM diagnosis AS d\n",
      "JOIN diagnosis_by_doctor AS dbd ON d.diagnosis_id = dbd.diagnosis_id\n",
      "JOIN doctors AS dr ON dbd.doctor_id = dr.doctor_id\n",
      "JOIN appointments AS a ON dr.doctor_id = a.doctor_id\n",
      "WHERE a.user_id = (SELECT user_id FROM appointments WHERE appointment_date = CURDATE())\n",
      "AND a.appointment_date > CURDATE();\n",
      "\n",
      "This query retrieves the recommendations for the diagnoses that the user's doctor has associated with them, and only returns the recommendations for appointments in the future. This should give the user an idea of what to bring or prepare for their next appointment.]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    }
   ],
   "source": [
    "from LLMs import MISTRAL_LLM_Chatbot\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "MODEL = \"open-mistral-7b\"\n",
    "mistral = MISTRAL_LLM_Chatbot(model_name=MODEL,api_key=MISTRAL_API_KEY)\n",
    "\n",
    "sql_predictions = []\n",
    "\n",
    "for q in testset_2:\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "\n",
    "        query = generate_query(llm=mistral, template=SUBCHAIN_PROMPT, question=q, db=DB2)\n",
    "        time.sleep(5)\n",
    "\n",
    "        response = generate_response(llm=mistral, query=query, template=FULLCHAIN_PROMPT, question=q, db=DB2)\n",
    "\n",
    "        query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "        response = response.replace(\"\\n\", \"\")\n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        sql_predictions.append((response, query, execution_time))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "\n",
    "        sql_predictions.append((\"Error\", query))\n",
    "    time.sleep(5)\n",
    "\n",
    "    output_filename = f\"evaluation_files/{MODEL}_2.csv\"\n",
    "    with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write each tuple in the list to the CSV file\n",
    "            writer.writerows(sql_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_first_element_to_txt('evaluation_files/open-mistral-7b_2.csv',\"output.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mistral large latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during chat completion: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"}\n",
      "Error during chat completion: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"}\n",
      "Error during chat completion: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"}\n",
      "Error during chat completion: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"}\n",
      "Error during chat completion: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"}\n",
      "Error during chat completion: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"}\n",
      "Error during chat completion: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"}\n",
      "Error during chat completion: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"}\n",
      "Error during chat completion: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"}\n",
      "Error during chat completion: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"}\n",
      "Error during chat completion: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"}\n",
      "Error during chat completion: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"}\n",
      "Error during chat completion: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"}\n",
      "Error during chat completion: API error occurred: Status 429\n",
      "{\"message\":\"Requests rate limit exceeded\"}\n"
     ]
    }
   ],
   "source": [
    "from LLMs import MISTRAL_LLM_Chatbot\n",
    "\n",
    "MODEL = \"mistral-large-latest\"\n",
    "mistral = MISTRAL_LLM_Chatbot(model_name=MODEL,api_key=MISTRAL_API_KEY)\n",
    "\n",
    "sql_predictions = []\n",
    "\n",
    "for q in testset_1:\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "\n",
    "        query = generate_query(llm=mistral, template=SUBCHAIN_PROMPT, question=q, db=DB)\n",
    "        response = generate_response(llm=mistral, query=query, template=FULLCHAIN_PROMPT, question=q, db=DB)\n",
    "\n",
    "        query = query.replace(\"\\n\", \"\")\n",
    "        response = response.replace(\"\\n\", \"\")\n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        sql_predictions.append((response, query, execution_time))\n",
    "\n",
    "    except Exception as e:\n",
    "        query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "\n",
    "        sql_predictions.append((\"Error\", query))\n",
    "\n",
    "    time.sleep(20)\n",
    "    output_filename = f\"evaluation_files/{MODEL}_1.csv\"\n",
    "    with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write each tuple in the list to the CSV file\n",
    "            writer.writerows(sql_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - ERROR\n",
      "1 - ERROR\n",
      "2 - ERROR\n",
      "3 - ERROR\n",
      "4 - ERROR\n",
      "5 - ERROR\n",
      "6 - ERROR\n",
      "7 - ERROR\n",
      "8 - ERROR\n",
      "9 - ERROR\n",
      "10 - ERROR\n",
      "11 - [('Normal',)]\n",
      "12 - [('Hemoglobin',), ('Cholesterol',), ('Glucose',)]\n",
      "13 - ERROR\n",
      "14 - ERROR\n",
      "15 - ERROR\n",
      "16 - ERROR\n",
      "17 - ERROR\n",
      "18 - ERROR\n",
      "19 - [(405.0,)]\n",
      "20 - ERROR\n",
      "21 - ERROR\n",
      "22 - ERROR\n",
      "23 - ERROR\n",
      "24 - ERROR\n",
      "25 - ERROR\n",
      "26 - [('%',)]\n",
      "27 - [(1,)]\n",
      "28 - ERROR\n",
      "29 - ERROR\n",
      "30 - [('Take Paracetamol',)]\n",
      "31 - [(5.5,)]\n",
      "32 - [('Normal',)]\n",
      "33 - \n",
      "34 - ERROR\n",
      "35 - ERROR\n",
      "36 - [('50-62',)]\n",
      "37 - [('michaelsmith@gmail.com',)]\n",
      "38 - [('janedoe@gmail.com',)]\n",
      "39 - ERROR\n",
      "40 - ERROR\n",
      "41 - ERROR\n",
      "42 - ERROR\n",
      "43 - ERROR\n",
      "44 - ERROR\n",
      "45 - ERROR\n",
      "46 - [(4,)]\n",
      "47 - [('mg/dL',)]\n",
      "48 - ERROR\n",
      "49 - ERROR\n",
      "50 - ERROR\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def read_second_element_from_csv(file_path):\n",
    "    second_elements = []\n",
    "    with open(file_path, mode='r', newline='') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            if len(row) > 1:  # Ensure there are at least two elements in the row\n",
    "                second_elements.append(row[1])\n",
    "    return second_elements\n",
    "\n",
    "# Example usage:\n",
    "result = read_second_element_from_csv('evaluation_files/open-mistral-7b_1.csv')\n",
    "\n",
    "for idx, query in enumerate(result):\n",
    "    try:\n",
    "        e = DB.run(query)\n",
    "        print(f\"{idx} - {e}\")\n",
    "    except:\n",
    "        print(f\"{idx} - ERROR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_first_element_to_txt(csv_file_path, txt_file_path):\n",
    "    with open(csv_file_path, mode='r', newline='') as csv_file:\n",
    "        reader = csv.reader(csv_file)\n",
    "        with open(txt_file_path, mode='w') as txt_file:\n",
    "            for row in reader:\n",
    "                if len(row) > 0:  # Ensure there's at least one element in the row\n",
    "                    txt_file.write(row[0] + '\\n')\n",
    "\n",
    "write_first_element_to_txt('evaluation_files/mistral-large-latest_2.csv', 'output.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during chat completion: Server disconnected without sending a response.\n",
      "Error during chat completion: Server disconnected without sending a response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(sqlite3.OperationalError) near \"An\": syntax error\n",
      "[SQL: An error occurred while processing your request: Server disconnected without sending a response.]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"mistral-large-latest\"\n",
    "mistral = MISTRAL_LLM_Chatbot(model_name=MODEL,api_key=MISTRAL_API_KEY)\n",
    "\n",
    "sql_predictions = []\n",
    "\n",
    "for q in testset_2:\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "\n",
    "        query = generate_query(llm=mistral, template=SUBCHAIN_PROMPT, question=q, db=DB2)\n",
    "        \n",
    "        time.sleep(5)\n",
    "\n",
    "        response = generate_response(llm=mistral, query=query, template=FULLCHAIN_PROMPT, question=q, db=DB2)\n",
    "\n",
    "        query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "        response = response.replace(\"\\n\", \"\")\n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        sql_predictions.append((response, query, execution_time))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "\n",
    "        sql_predictions.append((\"Error\", query))\n",
    "\n",
    "    time.sleep(15)\n",
    "    output_filename = f\"evaluation_files/{MODEL}_2.csv\"\n",
    "    with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write each tuple in the list to the CSV file\n",
    "            writer.writerows(sql_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_first_element_to_txt('evaluation_files/mistral-large-latest_2.csv',\"output.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Claude 3 Sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT first_name, last_name FROM \"USER\" LIMIT 1;\n"
     ]
    }
   ],
   "source": [
    "from LLMs import PREM_LLM_Chatbot\n",
    "import os\n",
    "\n",
    "MODEL = 'claude-3.5-sonnet'\n",
    "api_key = os.getenv(\"PREMAI_API_KEY\")\n",
    "claude = PREM_LLM_Chatbot(model_name=MODEL, api_key='POmkLj3PdIOiE8Z0tOv8cATgRrmLOu8B7z', project_id=5834)\n",
    "\n",
    "query = generate_query(llm=claude, template=SUBCHAIN_PROMPT, question=\"What is the user's name?\", db=DB)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMs import PREM_LLM_Chatbot\n",
    "import os\n",
    "MODEL = 'claude-3.5-sonnet'\n",
    "api_key = os.getenv(\"PREMAI_API_KEY\")\n",
    "claude = PREM_LLM_Chatbot(model_name=MODEL, api_key=api_key, project_id=5834)\n",
    "\n",
    "sql_predictions = []\n",
    "\n",
    "for q in testset_1:\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "\n",
    "        query = generate_query(llm=claude, template=SUBCHAIN_PROMPT, question=q, db=DB)\n",
    "        time.sleep(5)\n",
    "        response = generate_response(llm=claude, query=query, template=FULLCHAIN_PROMPT, question=q, db=DB)\n",
    "\n",
    "        query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "        response = response.replace(\"\\n\", \"\")\n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        sql_predictions.append((response, query, execution_time))\n",
    "\n",
    "    except Exception as e:\n",
    "        query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "\n",
    "        sql_predictions.append((\"Error\", query))\n",
    "\n",
    "    time.sleep(3)\n",
    "    output_filename = f\"evaluation_files/SQL/{MODEL}_1.csv\"\n",
    "    with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write each tuple in the list to the CSV file\n",
    "            writer.writerows(sql_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_first_element_to_txt(\"/Users/mymac/LLM/Personal-Medical-Assistant/backend/full_chain/evaluation_files/SQL/claude-3.5-sonnet_1.csv\", \"out.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMs import PREM_LLM_Chatbot\n",
    "\n",
    "MODEL = 'claude-3.5-sonnet'\n",
    "api_key = os.getenv(\"PREMAI_API_KEY\")\n",
    "claude = PREM_LLM_Chatbot(model_name=MODEL, api_key=api_key, project_id=5834)\n",
    "\n",
    "sql_predictions = []\n",
    "\n",
    "for q in testset_2:\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "\n",
    "        query = generate_query(llm=claude, template=SUBCHAIN_PROMPT, question=q, db=DB2)\n",
    "        response = generate_response(llm=claude, query=query, template=FULLCHAIN_PROMPT, question=q, db=DB2)\n",
    "\n",
    "        query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "        response = response.replace(\"\\n\", \"\")\n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        sql_predictions.append((response, query, execution_time))\n",
    "\n",
    "    except Exception as e:\n",
    "        query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "\n",
    "        sql_predictions.append((\"Error\", query))\n",
    "\n",
    "    time.sleep(15)\n",
    "    output_filename = f\"evaluation_files/SQL/{MODEL}_2.csv\"\n",
    "    with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write each tuple in the list to the CSV file\n",
    "            writer.writerows(sql_predictions)\n",
    "\n",
    "write_first_element_to_txt(\"/Users/mymac/LLM/Personal-Medical-Assistant/backend/full_chain/evaluation_files/SQL/claude-3.5-sonnet_2.csv\", \"out.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPT4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during chat completion: Error code: 400 - {'message': 'Invalid model, available models are: gpt-4, gpt-35-turbo, gpt-4o, gpt-4o-mini'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while processing your request: Error code: 400 - {'message': 'Invalid model, available models are: gpt-4, gpt-35-turbo, gpt-4o, gpt-4o-mini'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "MODEL = 'claude-3.5-sonnet'\n",
    "LANGDOCK_API_KEY = os.getenv(\"langdock_api_key\")\n",
    "LANGDOCK_BASE_URL = os.getenv(\"langdock_base_url\")\n",
    "gpt4 = langdock_LLM_Chatbot(model_name=MODEL, api_key=LANGDOCK_API_KEY, base_url=LANGDOCK_BASE_URL)\n",
    "\n",
    "query = generate_query(llm=gpt4, template=SUBCHAIN_PROMPT, question=\"What is the user's name?\", db=DB)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMs import PREM_LLM_Chatbot\n",
    "\n",
    "MODEL = 'gpt-4o'\n",
    "LANGDOCK_API_KEY = os.getenv(\"langdock_api_key\")\n",
    "LANGDOCK_BASE_URL = os.getenv(\"langdock_base_url\")\n",
    "gpt4 = langdock_LLM_Chatbot(model_name=MODEL, api_key=LANGDOCK_API_KEY, base_url=LANGDOCK_BASE_URL)\n",
    "\n",
    "sql_predictions = []\n",
    "\n",
    "for q in testset_1:\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "\n",
    "        query = generate_query(llm=claude, template=SUBCHAIN_PROMPT, question=q, db=DB)\n",
    "        response = generate_response(llm=claude, query=query, template=FULLCHAIN_PROMPT, question=q, db=DB)\n",
    "\n",
    "        query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "        response = response.replace(\"\\n\", \"\")\n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        sql_predictions.append((response, query, execution_time))\n",
    "\n",
    "    except Exception as e:\n",
    "        query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "\n",
    "        sql_predictions.append((\"Error\", query))\n",
    "\n",
    "    # time.sleep(15)\n",
    "    output_filename = f\"evaluation_files/{MODEL}_1.csv\"\n",
    "    with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write each tuple in the list to the CSV file\n",
    "            writer.writerows(sql_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_first_element_to_txt('evaluation_files/gpt-4o_1.csv', 'output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'gpt-4o'\n",
    "LANGDOCK_API_KEY = os.getenv(\"langdock_api_key\")\n",
    "LANGDOCK_BASE_URL = os.getenv(\"langdock_base_url\")\n",
    "claude = langdock_LLM_Chatbot(model_name=MODEL, api_key=LANGDOCK_API_KEY, base_url=LANGDOCK_BASE_URL)\n",
    "\n",
    "sql_predictions = []\n",
    "\n",
    "for q in testset_2:\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "\n",
    "        query = generate_query(llm=claude, template=SUBCHAIN_PROMPT, question=q, db=DB2)\n",
    "        response = generate_response(llm=claude, query=query, template=FULLCHAIN_PROMPT, question=q, db=DB2)\n",
    "\n",
    "        query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "        response = response.replace(\"\\n\", \"\")\n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        sql_predictions.append((response, query, execution_time))\n",
    "\n",
    "    except Exception as e:\n",
    "        query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "\n",
    "        sql_predictions.append((\"Error\", query))\n",
    "\n",
    "    # time.sleep(15)\n",
    "    output_filename = f\"evaluation_files/{MODEL}_2.csv\"\n",
    "    with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write each tuple in the list to the CSV file\n",
    "            writer.writerows(sql_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_first_element_to_txt('evaluation_files/gpt-4o_2.csv', 'output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine Tuned Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMs import MISTRAL_LLM_Chatbot\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "MODEL = \"ft:open-mistral-7b:5695b7ee:20240828:75b8298a\"\n",
    "mistral = MISTRAL_LLM_Chatbot(model_name=MODEL,api_key=MISTRAL_API_KEY)\n",
    "\n",
    "query = generate_query(llm=mistral, template=SUBCHAIN_PROMPT, question=\"What is the user's name?\", db=DB2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(sqlite3.OperationalError) no such column: T2.test_result\n",
      "[SQL: SELECT T2.test_result FROM reports AS T1 JOIN report_type AS T2 ON T1.report_type_id  =  T2.report_type_id JOIN medicine AS T3 ON T1.hospital_id  =  T3.hospital_id WHERE T1.first_name  =  \"Belen\" AND T1.last_name  =  \"Tavares\" AND T2.report_type_name  =  \"Blood report\" ORDER BY T1.report_date DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such table: appointment\n",
      "[SQL: SELECT T1.medicine_name ,  T2.dosage FROM medicine_by_diagnosis AS T1 JOIN medicine AS T2 ON T1.medicine_id = T2.medicine_id JOIN doctors AS T3 ON T3.doctor_id = T1.doctor_id JOIN appointment AS T4 ON T3.doctor_id = T4.doctor_id WHERE T4.user_id = (SELECT user_id FROM appointment WHERE appointment_date  =  CURDATE())]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T1.hospital_name\n",
      "[SQL: SELECT T1.hospital_name FROM appointments AS T1 JOIN hospitals AS T2 ON T1.hospital_id  =  T2.hospital_id ORDER BY T1.appointment_date DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T2.daily_frequency\n",
      "[SQL: SELECT T2.daily_frequency FROM medicine AS T1 JOIN medicine_by_diagnosis AS T2 ON T1.medicine_id  =  T2.medicine_id WHERE T1.medicine_name  =  'Lisinopril';]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.ProgrammingError) Incorrect number of bindings supplied. The current statement uses 1, and there are 0 supplied.\n",
      "[SQL: SELECT T1.interpretation FROM reports AS T1 JOIN user AS T2 ON T1.user_id = T2.user_id WHERE T2.user_id = ? AND T1.test_name = \"Creatinine\" ORDER BY T1.report_date DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "(sqlite3.OperationalError) no such column: T2.medicine_name\n",
      "[SQL: SELECT T2.medicine_name FROM diagnosis AS T1 JOIN medicine_by_diagnosis AS T2 ON T1.diagnosis_id  =  T2.diagnosis_id WHERE T1.diagnosis_name  =  \"Allergy\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such table: blood_tests\n",
      "[SQL: SELECT T2.platelet_count FROM reports AS T1 JOIN blood_tests AS T2 ON T1.report_id  =  T2.report_id WHERE T1.user_id  =  1 ORDER BY T1.report_date DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such table: doctor_by_diagnosis\n",
      "[SQL: SELECT T3.first_name ,  T3.last_name FROM appointments AS T1 JOIN diagnosis AS T2 ON T1.appointment_id  =  T2.appointment_id JOIN doctor_by_diagnosis AS T3 ON T2.diagnosis_id  =  T3.diagnosis_id JOIN doctors AS T4 ON T3.doctor_id  =  T4.doctor_id JOIN USER AS T5 ON T1.user_id  =  T5.user_id WHERE T5.birth_date LIKE \"%1990-12%\" AND T2.diagnosis_name  =  \"Flu\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: t1.dosage\n",
      "[SQL: SELECT t1.dosage ,  t1.daily_frequency FROM medicine_by_diagnosis AS t1 JOIN diagnosis AS t2 ON t1.diagnosis_id = t2.diagnosis_id WHERE t2.diagnosis_name  =  'Diabetes']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: t2.recommendations\n",
      "[SQL: SELECT t2.recommendations FROM appointments AS t1 JOIN diagnosis_by_doctor AS t2 ON t1.doctor_id  =  t2.doctor_id WHERE t1.user_id  =  1 AND t1.diagnosis_id  =  2]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: report_result\n",
      "[SQL: SELECT report_result FROM reports WHERE user_id  =  1 AND report_date  <=  DATEADD(day , -2 , GETDATE()) AND test_name  =  \"Urinalysis\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) near \"6\": syntax error\n",
      "[SQL: SELECT T1.report_id ,  T1.test_name ,  T1.test_result ,  T1.test_units ,  T1.test_reference_range ,  T1.interpretation ,  T2.report_date FROM reports AS T1 JOIN user AS T2 ON T1.user_id  =  T2.user_id WHERE T1.report_date  >=  DATE(DATE_SUB(now(), INTERVAL 6 MONTH))]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: t1.recommendations\n",
      "[SQL: SELECT t1.recommendations FROM diagnosis_by_doctor AS t1 JOIN diagnosis AS t2 ON t1.diagnosis_id = t2.diagnosis_id WHERE t2.diagnosis_name = \"cold\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T2.interpretation\n",
      "[SQL: SELECT T2.interpretation FROM reports AS T1 JOIN diagnosis AS T2 ON T1.diagnosis_id  =  T2.diagnosis_id WHERE T1.test_name  =  'Bilirubin' ORDER BY T1.report_date DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: t1.user_id\n",
      "[SQL: SELECT t2.phone_number FROM doctors AS t1 JOIN USER AS t2 ON t1.user_id  =  t2.user_id WHERE t1.first_name  =  \"John\" AND t1.last_name  =  \"Doe\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T1.specialization_name\n",
      "[SQL: SELECT T1.specialization_name FROM doctors AS T1 JOIN doctor_specialization AS T2 ON T1.specialization_id  =  T2.specialization_id WHERE T1.first_name  =  \"Michael\" AND T1.last_name  =  \"Smith\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: specialization_name\n",
      "[SQL: SELECT specialization_name FROM doctors WHERE first_name  =  \"Maria\" AND last_name  =  \"Garcia\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such table: hospital_clinics\n",
      "[SQL: SELECT T2.address_line FROM hospitals AS T1 JOIN hospital_clinics AS T2 ON T1.hospital_id  =  T2.hospital_id WHERE T1.hospital_name  =  'Cedars-Sinai Medical Center']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T2.diagnosis_name\n",
      "[SQL: SELECT T2.diagnosis_name ,  T3.medicine_name FROM appointments AS T1 JOIN diagnosis_by_doctor AS T2 ON T1.doctor_id  =  T2.doctor_id JOIN medicine_by_diagnosis AS T3 ON T2.diagnosis_id  =  T3.diagnosis_id WHERE T1.appointment_date  =  '2024-04-22']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    }
   ],
   "source": [
    "from LLMs import MISTRAL_LLM_Chatbot\n",
    "\n",
    "MODEL = \"ft:open-mistral-7b:5695b7ee:20240828:75b8298a\"\n",
    "mistral = MISTRAL_LLM_Chatbot(model_name=MODEL,api_key=MISTRAL_API_KEY)\n",
    "\n",
    "sql_predictions = []\n",
    "\n",
    "for q in testset_1:\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "\n",
    "        query = generate_query(llm=mistral, template=SUBCHAIN_PROMPT, question=q, db=DB)\n",
    "\n",
    "        time.sleep(5)\n",
    "        response = generate_response(llm=mistral, query=query, template=FULLCHAIN_PROMPT, question=q, db=DB)\n",
    "\n",
    "        query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "        response = response.replace(\"\\n\", \"\")\n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        sql_predictions.append((response, query, execution_time))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "\n",
    "        sql_predictions.append((\"Error\", query))\n",
    "    time.sleep(5)\n",
    "    output_filename = f\"evaluation_files/FT-mistral_SQL1_1.csv\"\n",
    "    with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write each tuple in the list to the CSV file\n",
    "            writer.writerows(sql_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_first_element_to_txt('evaluation_files/FT-mistral_SQL1_1.csv', 'output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(sqlite3.OperationalError) no such table: prescription\n",
      "[SQL: SELECT medicine_name ,  T2.dosage FROM prescription AS T1 JOIN medicine AS T2 ON T1.medicine_id  =  T2.medicine_id WHERE T1.user_id  =  1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T1.hospital_name\n",
      "[SQL: SELECT T1.hospital_name FROM appointments AS T1 JOIN USER AS T2 ON T1.user_id  =  T2.user_id ORDER BY T1.appointment_date DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such table: appointment\n",
      "[SQL: SELECT T1.dosage ,  T1.daily_frequency FROM medicine AS T1 JOIN medicine_by_diagnosis AS T2 ON T1.medicine_id  =  T2.medicine_id JOIN diagnosis AS T3 ON T2.diagnosis_id  =  T3.diagnosis_id JOIN appointment AS T4 ON T4.appointment_id  =  T3.appointment_id WHERE T4.user_id  =  1 AND T3.diagnosis_name  =  \"Type 2 Diabetes\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: medicine_daily_frequency\n",
      "[SQL: SELECT medicine_daily_frequency FROM medicine WHERE medicine_name = 'Iron polysaccharide';]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: t1.test_reference_range\n",
      "[SQL: SELECT t1.test_reference_range ,  t2.test_result FROM report_type AS t1 JOIN reports AS t2 ON t1.report_type_id  =  t2.report_type_id WHERE t2.test_name  =  'Blood glucose']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T2.test_reference_range\n",
      "[SQL: SELECT T1.report_id ,  T1.test_name ,  T1.test_result ,  T1.test_reference_range FROM reports AS T1 JOIN diagnosis_by_doctor AS T2 ON T1.user_id  =  T2.user_id WHERE T1.test_result NOT IN (SELECT T2.test_reference_range FROM reports AS T1 JOIN diagnosis_by_doctor AS T2 ON T1.user_id  =  T2.user_id) OR T1.test_result  <  (SELECT T2.test_reference_range FROM reports AS T1 JOIN diagnosis_by_doctor AS T2 ON T1.user_id  =  T2.user_id)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T1.doctor_id\n",
      "[SQL: SELECT T1.test_name FROM reports AS T1 JOIN diagnosis_by_doctor AS T2 ON T1.doctor_id  =  T2.doctor_id JOIN medicine_by_diagnosis AS T3 ON T3.diagnosis_id  =  T2.diagnosis_id JOIN medicine AS T4 ON T4.medicine_id  =  T3.medicine_id WHERE interpretation  =  'High']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T3.appointment_date\n",
      "[SQL: SELECT T3.appointment_date FROM appointments AS T1 JOIN diagnosis_by_doctor AS T2 ON T1.doctor_id  =  T2.doctor_id JOIN diagnosis AS T3 ON T2.diagnosis_id  =  T3.diagnosis_id WHERE T3.diagnosis_name  =  'Liraglutide (GLP-1 Receptor Agonists)']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: medicine_dosage\n",
      "[SQL: SELECT medicine_dosage FROM medicine_by_diagnosis WHERE medicine_id = (SELECT medicine_id FROM medicine_by_diagnosis WHERE diagnosis_id = (SELECT diagnosis_id FROM diagnosis_by_doctor WHERE doctor_id = (SELECT doctor_id FROM appointments WHERE appointment_id = (SELECT appointment_id FROM appointments WHERE user_id = 1))))]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T1.medicine_name\n",
      "[SQL: SELECT T1.medicine_name ,  T2.test_name ,  T3.diagnosis_name FROM medicine_by_diagnosis AS T1 JOIN reports AS T2 ON T1.medicine_id = T2.medicine_id JOIN diagnosis AS T3 ON T1.diagnosis_id = T3.diagnosis_id WHERE T2.user_id = 1 AND T2.hospital_id = 1 AND T2.interpretation != 'Normal']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T1.diagnose_id\n",
      "[SQL: SELECT T1.diagnosis_name ,  T2.test_result FROM diagnosis AS T1 JOIN reports AS T2 ON T1.diagnose_id  =  T2.diagnose_id WHERE T1.diagnosis_name  =  'Diabetes Type 2']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T2.user_id\n",
      "[SQL: SELECT T1.test_result FROM reports AS T1 JOIN diagnosis AS T2 ON T1.user_id  =  T2.user_id JOIN medicine AS T3 ON T2.diagnosis_id  =  T3.diagnosis_id JOIN medicine_by_diagnosis AS T4 ON T3.medicine_id  =  T4.medicine_id JOIN diagnosis_by_doctor AS T5 ON T4.diagnosis_id  =  T5.diagnosis_id JOIN doctors AS T6 ON T5.doctor_id  =  T6.doctor_id WHERE T1.test_name  =  'Hemoglobin A1c']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T3.recommended_by\n",
      "[SQL: SELECT T1.dosage ,  T1.daily_frequency FROM medicine AS T1 JOIN medicine_by_diagnosis AS T2 ON T1.medicine_id = T2.medicine_id JOIN diagnosis AS T3 ON T2.diagnosis_id = T3.diagnosis_id JOIN appointments AS T4 ON T4.doctor_id = T3.recommended_by WHERE T3.diagnosis_name  =  \"Diabetes Type 2\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: report_type_name\n",
      "[SQL: SELECT report_date ,  test_name ,  test_result ,  test_units ,  test_reference_range ,  report_type_name FROM reports WHERE user_id  =  1 AND report_date  >=  DATEADD(month , -1 , GETDATE())]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T2.report_id\n",
      "[SQL: SELECT interpretation FROM reports WHERE report_id IN (SELECT report_id FROM reports AS T1 JOIN appointments AS T2 ON T1.report_id  =  T2.report_id WHERE T1.user_id  =  1) AND test_name  =  'Hemoglobin A1c']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such table: USER_HOSPITALS\n",
      "[SQL: SELECT T2.hospital_name ,  T2.phone_number FROM hospitals AS T1 JOIN USER_HOSPITALS AS T2 ON T1.hospital_id  =  T2.hospital_id WHERE T1.hospital_name  =  \"Virginia Hospital Center\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.ProgrammingError) Incorrect number of bindings supplied. The current statement uses 1, and there are 0 supplied.\n",
      "[SQL: SELECT first_name ,  last_name ,  gender ,  birth_date ,  phone_number FROM USER WHERE user_id = ?]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n",
      "(sqlite3.OperationalError) no such column: T1.hospital_name\n",
      "[SQL: SELECT T1.hospital_name FROM appointments AS T1 JOIN doctors AS T2 ON T1.doctor_id = T2.doctor_id WHERE T2.first_name  =  'Drew' AND T1.appointment_date LIKE '2024%' LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: t1.user_id\n",
      "[SQL: SELECT count(*) FROM medicine AS t2 JOIN medicine_by_diagnosis AS t1 ON t2.medicine_id  =  t1.medicine_id WHERE t1.user_id  =  1;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) near \"1\": syntax error\n",
      "[SQL: SELECT T1.first_name ,  T1.last_name ,  T2.appointment_date FROM appointments AS T1 JOIN doctors AS T2 ON T1.doctor_id  =  T2.doctor_id WHERE T1.appointment_date  >  DATE_SUB(CURDATE() , INTERVAL 1 DAY) ORDER BY T1.appointment_date ASC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T1.phone_number\n",
      "[SQL: SELECT T1.phone_number FROM medicine AS T1 JOIN medicine_by_diagnosis AS T2 ON T1.medicine_id  =  T2.medicine_id JOIN diagnosis AS T3 ON T3.diagnosis_id  =  T2.diagnosis_id JOIN diagnosis_by_doctor AS T4 ON T3.diagnosis_id  =  T4.diagnosis_id JOIN doctors AS T1_1 ON T1_1.doctor_id  =  T4.doctor_id WHERE T1.medicine_name  =  \"Metformin\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: t3.diagnosis_name\n",
      "[SQL: SELECT t3.diagnosis_name FROM appointments AS t1 JOIN diagnosis AS t2 ON t1.diagnosis_id  =  t2.diagnosis_id JOIN diagnosis_by_doctor AS t3 ON t2.diagnosis_id  =  t3.diagnosis_id WHERE t1.user_id  =  1;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: Medicine_name\n",
      "[SQL: SELECT Medicine_name FROM medicine_by_diagnosis WHERE diagnosis_id IN (SELECT diagnosis_id FROM diagnosis WHERE diagnosis_name = 'Diabetes Type 2') AND Medicine_name NOT IN ('Metformin')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T2.daily_frequency\n",
      "[SQL: SELECT T1.medicine_name ,  T2.daily_frequency ,  T3.dosage FROM medicine AS T1 JOIN medicine_by_diagnosis AS T2 ON T1.medicine_id  =  T2.medicine_id JOIN appointments AS T3 ON T2.user_id  =  T3.user_id AND T2.appointment_id  =  T3.appointment_id WHERE T1.medicine_name NOT IN ('Metformin' ,  'Glyburide' ,  'Liraglutide (GLP-1 Receptor Agonists)') AND T2.daily_frequency  <  1 OR T1.medicine_name NOT IN ('Metformin' ,  'Glyburide' ,  'Liraglutide (GLP-1 Receptor Agonists)') AND T2.daily_frequency  =  1 AND T2.dosage  <  1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) near \"%\": syntax error\n",
      "[SQL: SELECT diagnosis_name ,  recommendations FROM diagnosis WHERE recommendations NOT LIKE %'%]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such table: users\n",
      "[SQL: SELECT T1.hospital_address_line FROM appointments AS T1 JOIN users AS T2 ON T1.user_id  =  T2.user_id ORDER BY T1.appointment_date DESC LIMIT 1 ;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    }
   ],
   "source": [
    "from LLMs import MISTRAL_LLM_Chatbot\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "MODEL = \"ft:open-mistral-7b:5695b7ee:20240828:75b8298a\"\n",
    "mistral = MISTRAL_LLM_Chatbot(model_name=MODEL,api_key=MISTRAL_API_KEY)\n",
    "\n",
    "sql_predictions = []\n",
    "\n",
    "for q in testset_2:\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "\n",
    "        query = generate_query(llm=mistral, template=SUBCHAIN_PROMPT, question=q, db=DB2)\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "\n",
    "        response = generate_response(llm=mistral, query=query, template=FULLCHAIN_PROMPT, question=q, db=DB2)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "\n",
    "        query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "        response = response.replace(\"\\n\", \"\")\n",
    "\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        sql_predictions.append((response, query, execution_time))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "\n",
    "        sql_predictions.append((\"Error\", query))\n",
    "\n",
    "    output_filename = f\"evaluation_files/{MODEL}1_2.csv\"\n",
    "    time.sleep(5)\n",
    "    with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write each tuple in the list to the CSV file\n",
    "            writer.writerows(sql_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_first_element_to_txt('evaluation_files/FT-mistral_SQL1_2.csv', 'output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FT2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(sqlite3.OperationalError) no such column: T3.dosage\n",
      "[SQL: SELECT T2.diagnosis_name ,  T3.dosage FROM appointments AS T1 JOIN diagnosis AS T2 ON T1.diagnosis_id  =  T2.diagnosis_id JOIN medicine_by_diagnosis AS T3 ON T2.diagnosis_id  =  T3.diagnosis_id WHERE T1.user_id  =  1;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T1.hospital_name\n",
      "[SQL: SELECT T1.hospital_name FROM appointments AS T1 JOIN doctors AS T2 ON T1.doctor_id  =  T2.doctor_id WHERE T1.appointment_date  =  (SELECT appointment_date FROM appointments WHERE user_id  =  1 ORDER BY appointment_date DESC LIMIT 1)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: t1.diagnosis_name\n",
      "[SQL: SELECT t3.recommendations FROM appointments AS t1 JOIN diagnosis_by_doctor AS t2 ON t1.doctor_id  =  t2.doctor_id JOIN diagnosis AS t3 ON t2.diagnosis_id  =  t3.diagnosis_id WHERE t1.diagnosis_name  =  \"Diabetes\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T1.phone_number\n",
      "[SQL: SELECT T1.phone_number FROM appointments AS T1 JOIN user AS T2 ON T1.user_id = T2.user_id ORDER BY T1.appointment_date DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T2.doctor_first_name\n",
      "[SQL: SELECT T1.diagnosis_name FROM diagnosis AS T1 JOIN diagnosis_by_doctor AS T2 ON T1.diagnosis_id  =  T2.diagnosis_id JOIN appointments AS T3 ON T2.doctor_id  =  T3.doctor_id WHERE T3.appointment_date  =  (SELECT appointment_date FROM appointments WHERE user_id  =  1 ORDER BY appointment_date DESC LIMIT 1) AND T2.doctor_first_name  =  'Jane' AND T2.doctor_last_name  =  'Doe';]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T3.interpretation\n",
      "[SQL: SELECT T1.test_name FROM reports AS T1 JOIN medicine_by_diagnosis AS T2 ON T1.report_id = T2.report_id JOIN diagnosis AS T3 ON T3.diagnosis_id = T2.diagnosis_id WHERE T3.interpretation = \"High\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T2.recommendations\n",
      "[SQL: SELECT T2.recommendations FROM diagnosis AS T1 JOIN diagnosis_by_doctor AS T2 ON T1.diagnosis_id = T2.diagnosis_id WHERE T1.diagnosis_name = \"allergy\";]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T2.address_line\n",
      "[SQL: SELECT T2.address_line FROM appointments AS T1 JOIN doctors AS T2 ON T1.doctor_id  =  T2.doctor_id JOIN hospitals AS T3 ON T2.hospital_id  =  T3.hospital_id WHERE T3.hospital_name  =  'Kindred Hospital Chicago North' AND T2.first_name = 'Belen' AND T2.last_name = 'Tavares';]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T2.report_id\n",
      "[SQL: SELECT T1.test_result FROM reports AS T1 JOIN medicine_by_diagnosis AS T2 ON T1.report_id  =  T2.report_id WHERE T1.test_name  =  \"Platelet count\" AND T1.user_id  =  (SELECT user_id FROM appointments ORDER BY appointment_date DESC LIMIT 1)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T1.first_name\n",
      "[SQL: SELECT T1.first_name ,  T1.last_name ,  T2.diagnosis_name FROM appointments AS T1 JOIN diagnosis_by_doctor AS T2 ON T1.doctor_id  =  T2.doctor_id WHERE T1.appointment_date LIKE '2023-%' AND T2.diagnosis_name  =  'Flu']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T1.city\n",
      "[SQL: SELECT T1.first_name ,  T1.last_name FROM doctors AS T1 JOIN appointments AS T2 ON T1.doctor_id  =  T2.doctor_id WHERE T2.hospital_id  =  4 AND T1.city  =  \"Miami\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such table: appointment_notes\n",
      "[SQL: SELECT count(*) FROM medicine_by_diagnosis AS T1 JOIN diagnosis AS T2 ON T1.diagnosis_id  =  T2.diagnosis_id JOIN appointment_notes AS T3 ON T3.appointment_id  =  T1.appointment_id WHERE T2.diagnosis_name  =  'Allergic reaction' AND T3.medicine_name  =  'Cetirizine']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) near \"2\": syntax error\n",
      "[SQL: SELECT T1.test_result FROM reports AS T1 JOIN appointments AS T2 ON T1.user_id  =  T2.user_id WHERE T2.appointment_date  =  date_sub(current_date ,  interval 2 day);]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: month\n",
      "[SQL: SELECT T1.report_date ,  T2.diagnosis_name FROM reports AS T1 JOIN diagnosis AS T2 ON T1.diagnosis_id  =  T2.diagnosis_id WHERE T1.report_date >= DATEADD(month , -6 , GETDATE())]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T2.recommendations\n",
      "[SQL: SELECT T2.recommendations FROM appointments AS T1 JOIN diagnosis_by_doctor AS T2 ON T1.doctor_id = T2.doctor_id WHERE T1.diagnosis_id = (SELECT diagnosis_id FROM diagnosis WHERE diagnosis_name = \"Hypertension\") AND T1.appointment_date = (SELECT appointment_date FROM appointments ORDER BY appointment_date DESC LIMIT 1)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T2.recommendations\n",
      "[SQL: SELECT T2.recommendations FROM diagnosis AS T1 JOIN diagnosis_by_doctor AS T2 ON T1.diagnosis_id  =  T2.diagnosis_id WHERE T1.diagnosis_name  =  \"Cold\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T3.Test_Result\n",
      "[SQL: SELECT T3.Test_Result FROM appointments AS T1 JOIN diagnosis AS T2 ON T1.diagnosis_id  =  T2.diagnosis_id JOIN medicine_by_diagnosis AS T3 ON T2.diagnosis_id  =  T3.diagnosis_id WHERE T1.Payment_Total  =  60 AND T1.appointment_date  =  (SELECT max(appointment_date) FROM appointments WHERE user_id  =  1) AND T2.Diagnosis_Name  =  \"Hemoglobin A1c\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such table: diagnoses\n",
      "[SQL: SELECT T2.interpretation FROM reports AS T1 JOIN diagnoses AS T2 ON T1.diagnosis_id  =  T2.diagnosis_id WHERE T1.test_name  =  \"Bilirubin\" AND T1.user_id = 1;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such table: doctors_specialization\n",
      "[SQL: SELECT T1.email FROM doctors AS T1 JOIN doctors_specialization AS T2 ON T1.specialization_id  =  T2.specialization_id WHERE T1.first_name  =  \"Michael\" AND T1.last_name  =  \"Smith\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T1.user_id\n",
      "[SQL: SELECT T1.phone_number FROM doctors AS T1 JOIN user AS T2 ON T1.user_id  =  T2.user_id WHERE T2.first_name  =  \"John\" AND T2.last_name  =  \"Doe\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T1.hospital_name\n",
      "[SQL: SELECT T1.hospital_name FROM doctors AS T1 JOIN hospitals AS T2 ON T1.hospital_id  =  T2.hospital_id WHERE T1.first_name  =  'Jane' AND T1.last_name  =  'Doe';]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T1.specialization_name\n",
      "[SQL: SELECT T1.specialization_name FROM doctors AS T1 JOIN doctor_specialization AS T2 ON T1.specialization_id  =  T2.specialization_id WHERE T1.first_name  =  \"Michael\" AND T1.last_name  =  \"Smith\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: t1.user_id\n",
      "[SQL: SELECT t2.specialization_name FROM doctors AS t1 JOIN doctor_specialization AS t2 ON t1.specialization_id  =  t2.specialization_id JOIN user AS t3 ON t1.user_id  =  t3.user_id WHERE t3.first_name  =  \"Maria\" AND t3.last_name  =  \"Garcia\";]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such table: doctor\n",
      "[SQL: SELECT T1.address_line FROM hospitals AS T1 JOIN doctor AS T2 ON T1.hospital_id  =  T2.hospital_id WHERE T2.hospital_name  =  'Cedars-Sinai Medical Center']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T2.appointment_id\n",
      "[SQL: SELECT T1.recommendations FROM diagnosis AS T1 JOIN diagnosis_by_doctor AS T2 ON T1.diagnosis_id  =  T2.diagnosis_id JOIN appointments AS T3 ON T3.appointment_id  =  T2.appointment_id WHERE T3.appointment_date  =  (SELECT appointment_date FROM appointments WHERE user_id = 1 AND payment_total = 60 GROUP BY appointment_date ORDER BY appointment_date LIMIT 1)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from LLMs import MISTRAL_LLM_Chatbot\n",
    "\n",
    "MODEL = \"ft:open-mistral-7b:5695b7ee:20240828:c1b970c2\"\n",
    "mistral = MISTRAL_LLM_Chatbot(model_name=MODEL,api_key=MISTRAL_API_KEY)\n",
    "\n",
    "sql_predictions = []\n",
    "\n",
    "for q in testset_1:\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "\n",
    "        query = generate_query(llm=mistral, template=SUBCHAIN_PROMPT, question=q, db=DB)\n",
    "\n",
    "        time.sleep(5)\n",
    "        response = generate_response(llm=mistral, query=query, template=FULLCHAIN_PROMPT, question=q, db=DB)\n",
    "\n",
    "        query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "        response = response.replace(\"\\n\", \"\")\n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        sql_predictions.append((response, query, execution_time))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "\n",
    "        sql_predictions.append((\"Error\", query))\n",
    "    time.sleep(5)\n",
    "    output_filename = f\"evaluation_files/FT2-mistral_SQL2_1.csv\"\n",
    "    with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write each tuple in the list to the CSV file\n",
    "            writer.writerows(sql_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_first_element_to_txt('evaluation_files/FT2-mistral_SQL2_1.csv', 'output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(sqlite3.OperationalError) no such column: report_date\n",
      "[SQL: SELECT test_result FROM reports AS T1 JOIN diagnosis_by_doctor AS T2 ON T1.user_id = T2.user_id WHERE T1.test_name = \"Hemoglobin\" AND T2.diagnosis_id = (SELECT diagnosis_id FROM diagnosis_by_doctor ORDER BY report_date DESC LIMIT 1)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T1.medicine_name\n",
      "[SQL: SELECT T1.medicine_name ,  T2.dosage FROM medicine_by_diagnosis AS T1 JOIN medicine AS T2 ON T1.medicine_id  =  T2.medicine_id JOIN appointments AS T3 ON T3.doctor_id  =  T1.doctor_id WHERE T3.appointment_date  =  \"2024-04-24\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such table: doctor\n",
      "[SQL: SELECT T1.hospital_name FROM appointments AS T1 JOIN doctor AS T2 ON T1.doctor_id = T2.doctor_id WHERE T1.appointment_date = (SELECT max(appointment_date) FROM appointments WHERE user_id = 1);]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T1.user_id\n",
      "[SQL: SELECT T2.dosage ,  T2.daily_frequency FROM medicine_by_diagnosis AS T1 JOIN medicine AS T2 ON T1.medicine_id  =  T2.medicine_id JOIN appointments AS T3 ON T3.user_id  =  T1.user_id WHERE T2.medicine_name  =  \"Sitagliptin\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T2.daily_frequency\n",
      "[SQL: SELECT T2.daily_frequency FROM medicine AS T1 JOIN medicine_by_diagnosis AS T2 ON T1.medicine_id  =  T2.medicine_id WHERE T1.medicine_name  =  'Iron polysaccharide']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such table: hospital\n",
      "[SQL: SELECT T2.phone_number FROM doctors AS T1 JOIN hospital AS T2 ON T1.hospital_id  =  T2.hospital_id WHERE T1.specialization_id  =  \"3\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such table: test_results\n",
      "[SQL: SELECT T2.test_reference_range ,  T3.test_result FROM reports AS T1 JOIN test_results AS T2 ON T1.test_id  =  T2.test_id JOIN diagnoses AS T3 ON T1.diagnosis_id  =  T3.diagnosis_id WHERE T3.diagnosis_name  =  'Diabetes Type 2' AND T1.user_id  =  1;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: t2.appointment_id\n",
      "[SQL: SELECT t1.appointment_date FROM appointments AS t1 JOIN diagnosis_by_doctor AS t2 ON t1.appointment_id = t2.appointment_id JOIN medicine_by_diagnosis AS t3 ON t2.diagnosis_id = t3.diagnosis_id JOIN medicine AS t4 ON t3.medicine_id = t4.medicine_id WHERE t4.medicine_name = \"Liraglutide (GLP-1 Receptor Agonists)\";]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T3.doctor_id\n",
      "[SQL: SELECT T1.dosage FROM medicine AS T1 JOIN medicine_by_diagnosis AS T2 ON T1.medicine_id  =  T2.medicine_id JOIN diagnosis AS T3 ON T2.diagnosis_id  =  T3.diagnosis_id JOIN doctors AS T4 ON T4.doctor_id  =  T3.doctor_id WHERE T4.first_name  =  \"Drew\" AND T4.last_name  =  \"Smith\"]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T7.user_id\n",
      "[SQL: SELECT T1.medicine_name FROM medicine AS T1 JOIN medicine_by_diagnosis AS T2 ON T1.medicine_id  =  T2.medicine_id JOIN diagnosis AS T3 ON T2.diagnosis_id  =  T3.diagnosis_id JOIN appointments AS T4 ON T4.user_id  =  T3.user_id WHERE T4.appointment_date  =  '2024-01-18' AND T3.diagnosis_name  =  'Diabetes Type 2' AND T1.dosage != (SELECT T5.dosage FROM medicine AS T5 JOIN medicine_by_diagnosis AS T6 ON T5.medicine_id  =  T6.medicine_id JOIN diagnosis AS T7 ON T6.diagnosis_id  =  T7.diagnosis_id JOIN appointments AS T8 ON T8.user_id  =  T7.user_id WHERE T8.appointment_date  =  '2024-04-24' AND T7.diagnosis_name  =  'Diabetes Type 2')]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such table: test_results\n",
      "[SQL: SELECT T1.test_result FROM reports AS T1 JOIN test_results AS T2 ON T1.test_id  =  T2.test_id WHERE T1.test_name  =  \"Platelet count\" AND T1.user_id  =  1 ORDER BY T1.report_date DESC LIMIT 1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T2.appointment_id\n",
      "[SQL: SELECT diagnosis_name FROM diagnosis AS T1 JOIN medicine_by_diagnosis AS T2 ON T1.diagnosis_id  =  T2.diagnosis_id JOIN reports AS T3 ON T2.appointment_id  =  T3.appointment_id WHERE T1.diagnosis_name  =  'Diabetes Type 2' AND T3.test_name  =  'Hemoglobin A1C' AND T3.test_result >= 6 AND T3.test_result < 8]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such table: blood_test\n",
      "[SQL: SELECT T1.hemoglobin_A1c ,  T2.interpretation FROM blood_test AS T1 JOIN test_results AS T2 ON T1.blood_test_id  =  T2.blood_test_id WHERE T1.patient_id  =  1]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) near \"1\": syntax error\n",
      "[SQL: SELECT T1.report_date ,  T2.report_type_name ,  T3.test_name ,  T3.test_result ,  T3.test_units FROM reports AS T1 JOIN report_type AS T2 ON T1.report_type_id  =  T2.report_type_id JOIN tests AS T3 ON T1.test_id  =  T3.test_id WHERE T1.report_date  >=  (DATE_SUB(CURDATE() , INTERVAL 1 MONTH))]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such table: user_appointments\n",
      "[SQL: SELECT appointment_date FROM appointments AS T1 JOIN doctors AS T2 ON T1.doctor_id  =  T2.doctor_id JOIN user_appointments AS T3 ON T1.appointment_id  =  T3.appointment_id WHERE T2.specialization_id  =  \"1\" AND T3.user_id = (SELECT user_id FROM appointments AS T1 JOIN doctors AS T2 ON T1.doctor_id  =  T2.doctor_id JOIN user_appointments AS T3 ON T1.appointment_id  =  T3.appointment_id WHERE T2.specialization_id  =  \"1\" GROUP BY T1.appointment_id ORDER BY count(*) DESC LIMIT 1)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T2.address_line\n",
      "[SQL: SELECT T2.address_line FROM appointments AS T1 JOIN doctors AS T2 ON T1.doctor_id  =  T2.doctor_id WHERE T2.hospital_id IN (SELECT hospital_id FROM hospitals WHERE hospital_name LIKE \"%Virginia%\")]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T1.address_line\n",
      "[SQL: SELECT T1.address_line FROM appointments AS T1 JOIN hospitals AS T2 ON T1.hospital_id  =  T2.hospital_id JOIN user AS T3 ON T1.user_id  =  T3.user_id WHERE T3.first_name  =  \"Drew\" AND T3.last_name  =  \"Smith\" AND T1.appointment_date LIKE \"2024-%\" AND T1.appointment_id  =  (SELECT appointment_id FROM appointments WHERE appointment_date LIKE \"2024-%\" AND user_id  =  (SELECT user_id FROM user WHERE first_name  =  \"Drew\" AND last_name  =  \"Smith\") ORDER BY appointment_date ASC LIMIT 1)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T1.first_name\n",
      "[SQL: SELECT T1.first_name ,  T1.last_name FROM appointments AS T1 JOIN doctors AS T2 ON T1.doctor_id = T2.doctor_id WHERE T1.appointment_date =  \"2024-04-24\";]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such table: appointment_dates\n",
      "[SQL: SELECT T2.appointment_date ,  T3.hospital_name FROM appointments AS T1 JOIN appointment_dates AS T2 ON T1.appointment_id  =  T2.appointment_id JOIN hospitals AS T3 ON T1.hospital_id  =  T3.hospital_id WHERE T1.user_id  =  \"1\" AND T2.appointment_date  =  (SELECT min(appointment_date) FROM appointments AS T4 JOIN appointment_dates AS T5 ON T4.appointment_id  =  T5.appointment_id WHERE T4.user_id  =  \"1\")]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) near \"OFFSET\": syntax error\n",
      "[SQL: SELECT T1.first_name ,  T1.last_name FROM appointments AS T1 JOIN doctors AS T2 ON T1.doctor_id  =  T2.doctor_id WHERE T1.appointment_date  =  (SELECT appointment_date FROM appointments ORDER BY appointment_date LIMIT 1 , 1 OFFSET (SELECT count(*) FROM appointments WHERE appointment_date  =  (SELECT appointment_date FROM appointments ORDER BY appointment_date LIMIT 1) + 1) )]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T2.first_name\n",
      "[SQL: SELECT T2.first_name ,  T2.last_name FROM medicine_by_diagnosis AS T1 JOIN medicine AS T2 ON T1.medicine_id  =  T2.medicine_id JOIN doctors AS T3 ON T1.doctor_id  =  T3.doctor_id WHERE T2.medicine_name  =  'Metformin']\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: user_id\n",
      "[SQL: SELECT medicine_name ,  dosage FROM medicine WHERE user_id = 1 EXCEPT SELECT T2.medicine_name ,  T2.dosage FROM medicine_by_diagnosis AS T1 JOIN medicine AS T2 ON T1.medicine_id  =  T2.medicine_id WHERE T1.diagnosis_id IN (SELECT diagnosis_id FROM diagnosis_by_doctor WHERE doctor_id = 1)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such column: T2.recommendations\n",
      "[SQL: SELECT T2.recommendations FROM appointments AS T1 JOIN diagnosis_by_doctor AS T2 ON T1.doctor_id = T2.doctor_id WHERE T1.appointment_date = (SELECT appointment_date FROM appointments ORDER BY appointment_date LIMIT 1)]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "(sqlite3.OperationalError) no such table: user_appointments\n",
      "[SQL: SELECT T1.appointment_date FROM appointments AS T1 JOIN user_appointments AS T2 ON T1.appointment_id  =  T2.appointment_id WHERE T2.user_id  =  1 ORDER BY T1.appointment_date DESC LIMIT 1;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    }
   ],
   "source": [
    "from LLMs import MISTRAL_LLM_Chatbot\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "MODEL = \"ft:open-mistral-7b:5695b7ee:20240828:c1b970c2\"\n",
    "mistral = MISTRAL_LLM_Chatbot(model_name=MODEL,api_key=MISTRAL_API_KEY)\n",
    "\n",
    "sql_predictions = []\n",
    "\n",
    "for q in testset_2:\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "\n",
    "        query = generate_query(llm=mistral, template=SUBCHAIN_PROMPT, question=q, db=DB2)\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "\n",
    "        response = generate_response(llm=mistral, query=query, template=FULLCHAIN_PROMPT, question=q, db=DB2)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "\n",
    "        query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "        response = response.replace(\"\\n\", \"\")\n",
    "\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        sql_predictions.append((response, query, execution_time))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        query = query.replace(\"\\n\", \"\").replace(\"  \", \"\")\n",
    "\n",
    "        sql_predictions.append((\"Error\", query))\n",
    "\n",
    "    output_filename = f\"evaluation_files/FT2-mistral7b_SQL_2.csv\"\n",
    "    time.sleep(5)\n",
    "    with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write each tuple in the list to the CSV file\n",
    "            writer.writerows(sql_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_first_element_to_txt('evaluation_files/FT2-mistral7b_SQL_2.csv', 'output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG QUERY PIPELINE (JSON METHOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "from LLMs import langdock_LLM_Chatbot\n",
    "from helper import get_current_time\n",
    "\n",
    "RAG_CONTEXT = \"\"\"\n",
    "You are a helpful medical assistant. \n",
    "\n",
    "Given the user question and the user medical data, answer the user's question to the best of your ability. The data is an sql database in JSON format. The data is the users personal medical data, so the user may use personal pronouns like 'my' when querying. It is okay to say you do not have the information the user is looking for.\n",
    "\n",
    "Answer the users question to the best of your ability, ensuring to ONLY respond with information you find in the provided dataset. \n",
    "\n",
    "User question: {question}\n",
    "User medical data: {user_data}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generate_RAG_query(llm, template, question, user_data):\n",
    "    \"\"\"\n",
    "    Generates an SQL query.\n",
    "\n",
    "    Parameters:\n",
    "    llm (Class): Class instance of large language model\n",
    "    template (str): Prompt for llm to follow\n",
    "    question (str): User's question for the database\n",
    "\n",
    "    Returns:\n",
    "    out (str): LLM response\n",
    "    \"\"\"\n",
    "    current_date = get_current_time()\n",
    "    prompt = template.format(question=question, user_data=user_data, current_date=current_date)       #format template to include all necessary information (schema, question)\n",
    "    answer = llm.chat_completion(prompt, question)         #generates sql query\n",
    "\n",
    "    return answer\n",
    "\n",
    "\n",
    "def read_json_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads a JSON file and returns its contents as a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    file_path (str): The path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "    dict: The contents of the JSON file as a dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "belen = 'med_assist.json'\n",
    "drew = 'drew.json'\n",
    "\n",
    "USER_DATA_1 = read_json_file(belen)\n",
    "USER_DATA_2 = read_json_file(drew)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPT4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMs import langdock_LLM_Chatbot\n",
    "MODEL = \"gpt-4o\"\n",
    "llm_langdock =langdock_LLM_Chatbot(model_name=MODEL, api_key=LANGDOCK_API_KEY, base_url=LANGDOCK_BASE_URL) #instantiate anyscale llm object\n",
    "\n",
    "\n",
    "sql_predictions = []\n",
    "for q in testset_1:\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = generate_query(llm=llm_langdock, template=context, user_data=USER_DATA_1, question=q)\n",
    "\n",
    "\n",
    "        response = response.replace(\"\\n\", \"\")\n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        sql_predictions.append((response, execution_time))\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        sql_predictions.append((\"Error\"))\n",
    "\n",
    "    # time.sleep(15)\n",
    "    output_filename = f\"evaluation_files/JSON/{MODEL}_1.csv\"\n",
    "    with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write each tuple in the list to the CSV file\n",
    "            writer.writerows(sql_predictions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMs import langdock_LLM_Chatbot\n",
    "MODEL = \"gpt-4o\"\n",
    "llm_langdock =langdock_LLM_Chatbot(model_name=MODEL, api_key=LANGDOCK_API_KEY, base_url=LANGDOCK_BASE_URL) #instantiate anyscale llm object\n",
    "\n",
    "\n",
    "sql_predictions = []\n",
    "for q in testset_2:\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = generate_query(llm=llm_langdock, template=context, user_data=USER_DATA_2, question=q)\n",
    "\n",
    "\n",
    "        response = response.replace(\"\\n\", \"\")\n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        sql_predictions.append((response, execution_time))\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        sql_predictions.append((\"Error\"))\n",
    "\n",
    "    # time.sleep(15)\n",
    "    output_filename = f\"evaluation_files/JSON/{MODEL}_2.csv\"\n",
    "    with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write each tuple in the list to the CSV file\n",
    "            writer.writerows(sql_predictions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_first_element_to_txt(\"/Users/mymac/LLM/Personal-Medical-Assistant/backend/full_chain/evaluation_files/JSON/gpt-4o_1.csv\",\"output.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Llama3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Based on the provided data, the user's name is 'Belen Tavares'.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from LLMs import OCTOAI_LLM_Chatbot\n",
    "OCTOAI_API_KEY = os.getenv(\"OCTOAI_TOKEN\")\n",
    "\n",
    "MODEL = \"meta-llama-3-8b-instruct\"\n",
    "\n",
    "llm_octo =OCTOAI_LLM_Chatbot(model_name=MODEL, api_key=OCTOAI_API_KEY)\n",
    "\n",
    "generate_RAG_query(llm=llm_octo, template=RAG_CONTEXT, question=\"What is the user's name?\", user_data=USER_DATA_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMs import OCTOAI_LLM_Chatbot\n",
    "MODEL = \"meta-llama-3-8b-instruct\"\n",
    "llm_octo =OCTOAI_LLM_Chatbot(model_name=MODEL, api_key=OCTOAI_API_KEY)\n",
    "\n",
    "\n",
    "predictions = []\n",
    "for q in testset_1:\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = generate_RAG_query(llm=llm_octo, template=RAG_CONTEXT, question=q, user_data=USER_DATA_1)\n",
    "\n",
    "\n",
    "        response = response.replace(\"\\n\", \"\")       #format for easy evaluation \n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        predictions.append((response, execution_time))\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        predictions.append((\"Error\"))\n",
    "\n",
    "    time.sleep(5)\n",
    "    output_filename = f\"evaluation_files/JSON/{MODEL}_1.csv\"\n",
    "    with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write each tuple in the list to the CSV file\n",
    "            writer.writerows(predictions)\n",
    "\n",
    "\n",
    "write_first_element_to_txt(f'evaluation_files/JSON/{MODEL}_1.csv', 'output.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_first_element_to_txt(f'evaluation_files/JSON/{MODEL}_1.csv', 'output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMs import OCTOAI_LLM_Chatbot\n",
    "MODEL = \"meta-llama-3-8b-instruct\"\n",
    "llm_octo =OCTOAI_LLM_Chatbot(model_name=MODEL, api_key=OCTOAI_API_KEY)\n",
    "\n",
    "\n",
    "predictions = []\n",
    "for q in testset_2:\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = generate_RAG_query(llm=llm_octo, template=RAG_CONTEXT, question=q, user_data=USER_DATA_2)\n",
    "\n",
    "\n",
    "        response = response.replace(\"\\n\", \"\")       #format for easy evaluation \n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        predictions.append((response, execution_time))\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        predictions.append(str(e))\n",
    "\n",
    "    time.sleep(5)\n",
    "    output_filename = f\"evaluation_files/JSON/{MODEL}_2.csv\"\n",
    "    with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write each tuple in the list to the CSV file\n",
    "            writer.writerows(predictions)\n",
    "\n",
    "\n",
    "write_first_element_to_txt(f'evaluation_files/JSON/{MODEL}_2.csv', 'output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mistral Large Latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The user's name is Drew Smith.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from LLMs import MISTRAL_LLM_Chatbot\n",
    "\n",
    "MODEL = \"mistral-large-latest\"\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "\n",
    "mistral = MISTRAL_LLM_Chatbot(model_name=MODEL,api_key=MISTRAL_API_KEY)\n",
    "\n",
    "generate_RAG_query(llm=mistral, template=RAG_CONTEXT, question=\"what is the user's name?\", user_data=USER_DATA_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMs import MISTRAL_LLM_Chatbot\n",
    "\n",
    "MODEL = \"mistral-large-latest\"\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "\n",
    "mistral = MISTRAL_LLM_Chatbot(model_name=MODEL,api_key=MISTRAL_API_KEY)\n",
    "\n",
    "predictions = []\n",
    "for q in testset_1:\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = generate_RAG_query(llm=llm_octo, template=RAG_CONTEXT, question=q, user_data=USER_DATA_1)\n",
    "\n",
    "\n",
    "        response = response.replace(\"\\n\", \"\")       #format for easy evaluation \n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        predictions.append((response, execution_time))\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        predictions.append((\"Error\"))\n",
    "\n",
    "    time.sleep(5)\n",
    "    output_filename = f\"evaluation_files/JSON/{MODEL}_1.csv\"\n",
    "    with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write each tuple in the list to the CSV file\n",
    "            writer.writerows(predictions)\n",
    "\n",
    "\n",
    "write_first_element_to_txt(f'evaluation_files/JSON/{MODEL}_1.csv', 'output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMs import MISTRAL_LLM_Chatbot\n",
    "\n",
    "MODEL = \"mistral-large-latest\"\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "\n",
    "mistral = MISTRAL_LLM_Chatbot(model_name=MODEL,api_key=MISTRAL_API_KEY)\n",
    "\n",
    "predictions = []\n",
    "for q in testset_2:\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = generate_RAG_query(llm=llm_octo, template=RAG_CONTEXT, question=q, user_data=USER_DATA_2)\n",
    "\n",
    "\n",
    "        response = response.replace(\"\\n\", \"\")       #format for easy evaluation \n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        predictions.append((response, execution_time))\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        predictions.append((\"Error\"))\n",
    "\n",
    "    time.sleep(5)\n",
    "    output_filename = f\"evaluation_files/JSON/{MODEL}_2.csv\"\n",
    "    with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write each tuple in the list to the CSV file\n",
    "            writer.writerows(predictions)\n",
    "\n",
    "\n",
    "write_first_element_to_txt(f'evaluation_files/JSON/{MODEL}_2.csv', 'output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mistral 7b open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMs import MISTRAL_LLM_Chatbot\n",
    "\n",
    "MODEL = \"open-mistral-7b\"\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "\n",
    "mistral = MISTRAL_LLM_Chatbot(model_name=MODEL,api_key=MISTRAL_API_KEY)\n",
    "\n",
    "generate_RAG_query(llm=mistral, template=RAG_CONTEXT, question=\"what is the user's name?\", user_data=USER_DATA_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMs import MISTRAL_LLM_Chatbot\n",
    "MODEL = \"open-mistral-7b\"\n",
    "mistral = MISTRAL_LLM_Chatbot(model_name=MODEL,api_key=MISTRAL_API_KEY)\n",
    "\n",
    "\n",
    "predictions = []\n",
    "for q in testset_1:\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = generate_RAG_query(llm=mistral, template=RAG_CONTEXT, question=q, user_data=USER_DATA_1)\n",
    "\n",
    "\n",
    "        response = response.replace(\"\\n\", \"\")       #format for easy evaluation \n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        predictions.append((response, execution_time))\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        predictions.append((\"Error\"))\n",
    "\n",
    "    time.sleep(5)\n",
    "    output_filename = f\"evaluation_files/JSON/{MODEL}_1.csv\"\n",
    "    with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write each tuple in the list to the CSV file\n",
    "            writer.writerows(predictions)\n",
    "\n",
    "\n",
    "write_first_element_to_txt(f'evaluation_files/JSON/{MODEL}_1.csv', 'output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMs import MISTRAL_LLM_Chatbot\n",
    "\n",
    "MODEL = \"open-mistral-7b\"\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "\n",
    "mistral = MISTRAL_LLM_Chatbot(model_name=MODEL,api_key=MISTRAL_API_KEY)\n",
    "\n",
    "predictions = []\n",
    "for q in testset_2:\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = generate_RAG_query(llm=llm_octo, template=RAG_CONTEXT, question=q, user_data=USER_DATA_2)\n",
    "\n",
    "\n",
    "        response = response.replace(\"\\n\", \"\")       #format for easy evaluation \n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        predictions.append((response, execution_time))\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        predictions.append((\"Error\"))\n",
    "\n",
    "    time.sleep(5)\n",
    "    output_filename = f\"evaluation_files/JSON/{MODEL}_2.csv\"\n",
    "    with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write each tuple in the list to the CSV file\n",
    "            writer.writerows(predictions)\n",
    "\n",
    "\n",
    "write_first_element_to_txt(f'evaluation_files/JSON/{MODEL}_2.csv', 'output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FT Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Drew Smith'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from LLMs import MISTRAL_LLM_Chatbot\n",
    "MODEL = \"ft:open-mistral-7b:5695b7ee:20240828:c1b970c2\"\n",
    "\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "\n",
    "mistral = MISTRAL_LLM_Chatbot(model_name=MODEL,api_key=MISTRAL_API_KEY)\n",
    "\n",
    "generate_RAG_query(llm=mistral, template=RAG_CONTEXT, question=\"what is the user's name?\", user_data=USER_DATA_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"ft:open-mistral-7b:5695b7ee:20240828:c1b970c2\"\n",
    "mistral = MISTRAL_LLM_Chatbot(model_name=MODEL,api_key=MISTRAL_API_KEY)\n",
    "\n",
    "\n",
    "predictions = []\n",
    "for q in testset_1:\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = generate_RAG_query(llm=mistral, template=RAG_CONTEXT, question=q, user_data=USER_DATA_1)\n",
    "\n",
    "        response = response.replace(\"\\n\", \"\")       #format for easy evaluation \n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        predictions.append((response, execution_time))\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        predictions.append((\"Error\"))\n",
    "\n",
    "    time.sleep(5)\n",
    "    output_filename = f\"evaluation_files/JSON/{MODEL}_1.csv\"\n",
    "    with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write each tuple in the list to the CSV file\n",
    "            writer.writerows(predictions)\n",
    "\n",
    "\n",
    "write_first_element_to_txt(f'evaluation_files/JSON/{MODEL}_1.csv', 'output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LLMs import MISTRAL_LLM_Chatbot\n",
    "\n",
    "MODEL = \"ft:open-mistral-7b:5695b7ee:20240828:c1b970c2\"\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "\n",
    "mistral = MISTRAL_LLM_Chatbot(model_name=MODEL,api_key=MISTRAL_API_KEY)\n",
    "\n",
    "predictions = []\n",
    "for q in testset_2:\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = generate_RAG_query(llm=llm_octo, template=RAG_CONTEXT, question=q, user_data=USER_DATA_2)\n",
    "\n",
    "\n",
    "        response = response.replace(\"\\n\", \"\")       #format for easy evaluation \n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        predictions.append((response, execution_time))\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        predictions.append((\"Error\"))\n",
    "\n",
    "    time.sleep(5)\n",
    "    output_filename = f\"evaluation_files/JSON/{MODEL}_2.csv\"\n",
    "    with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write each tuple in the list to the CSV file\n",
    "            writer.writerows(predictions)\n",
    "\n",
    "\n",
    "write_first_element_to_txt(f'evaluation_files/JSON/{MODEL}_2.csv', 'output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Claude 3.5 Sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What was the result of my Hemoglobin A1c in the last report?',\n",
       " 'What was the interpretation of my Hemoglobin A1c in the last report?',\n",
       " 'What was the interpretation of my bilirubin levels in the last report?',\n",
       " \"What are all the dates of all the appointments I've had with cardiologists?\",\n",
       " 'How many times have I visited Cedars-Sinai for appointments?',\n",
       " 'What are the normal reference ranges for neutrophils?',\n",
       " 'What is the email of doctor Michael Smith?',\n",
       " 'What is the email of doctor Jane Doe?',\n",
       " 'What is the phone number of doctor John Doe?',\n",
       " 'What is the phone number of doctor Maria Garcia?',\n",
       " 'What hospital does Jane Doe work at?',\n",
       " 'What kind of doctor is Michael Smith?',\n",
       " 'What specialization is Maria Garcia?',\n",
       " 'What is the phone number of NYU Langone?',\n",
       " 'What is the address of Cedars-Sinai Medical Center?',\n",
       " 'How many hospitals do I have listed?',\n",
       " 'What units is the Cholesterol test in?',\n",
       " 'When is my next upcoming appointment?',\n",
       " 'Is there anything I should bring/prepare for my next appointment?',\n",
       " 'Where is my next appointment?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = testset_1[31:]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during chat completion: [Errno 54] Connection reset by peer\n"
     ]
    }
   ],
   "source": [
    "from LLMs import PREM_LLM_Chatbot\n",
    "import os\n",
    "import time\n",
    "\n",
    "MODEL = 'claude-3.5-sonnet'\n",
    "# api_key = os.getenv(\"PREMAI_API_KEY\")\n",
    "claude = PREM_LLM_Chatbot(model_name=MODEL, api_key=\"XM6XfOysbSOqDOkUjSLP5ASh5m7QqS9ZMr\", project_id=5975)\n",
    "\n",
    "predictions = []\n",
    "SET = testset_1[31:]\n",
    "for q in SET:\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = generate_RAG_query(llm=claude, template=RAG_CONTEXT, question=q, user_data=USER_DATA_1)\n",
    "\n",
    "\n",
    "        response = response.replace(\"\\n\", \"\")       #format for easy evaluation \n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        predictions.append((response, execution_time))\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        predictions.append((\"Error\"))\n",
    "\n",
    "    time.sleep(5)\n",
    "    output_filename = f\"evaluation_files/JSON/{MODEL}_1.csv\"\n",
    "    with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write each tuple in the list to the CSV file\n",
    "            writer.writerows(predictions)\n",
    "\n",
    "\n",
    "write_first_element_to_txt(f'evaluation_files/JSON/{MODEL}_1.csv', 'output.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_first_element_to_txt(f'evaluation_files/JSON/{MODEL}_1.csv', 'output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during chat completion: Unexpected status code: 502, reason: b'<html>\\r\\n<head><title>502 Bad Gateway</title></head>\\r\\n<body>\\r\\n<center><h1>502 Bad Gateway</h1></center>\\r\\n<hr><center>cloudflare</center>\\r\\n</body>\\r\\n</html>\\r\\n'\n"
     ]
    }
   ],
   "source": [
    "from LLMs import PREM_LLM_Chatbot\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "\n",
    "MODEL = 'claude-3.5-sonnet'\n",
    "# MODEL = \"gpt-4o\"\n",
    "api_key = \"86T7rH6dZy5EpVwMzenrFJw9qPPlFYih0e\"\n",
    "claude = PREM_LLM_Chatbot(model_name=MODEL, api_key=api_key, project_id=5970)\n",
    "\n",
    "predictions = []\n",
    "for q in testset_2:\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        response = generate_RAG_query(llm=claude, template=RAG_CONTEXT, question=q, user_data=USER_DATA_2)\n",
    "\n",
    "\n",
    "        response = response.replace(\"\\n\", \"\")       #format for easy evaluation \n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "\n",
    "        predictions.append((response, execution_time))\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        predictions.append((\"Error\"))\n",
    "\n",
    "    time.sleep(5)\n",
    "    output_filename = f\"evaluation_files/JSON/{MODEL}_2.csv\"\n",
    "    with open(output_filename, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Write each tuple in the list to the CSV file\n",
    "            writer.writerows(predictions)\n",
    "\n",
    "\n",
    "write_first_element_to_txt(f'evaluation_files/JSON/{MODEL}_2.csv', 'output.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
