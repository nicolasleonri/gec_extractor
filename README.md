# Newspaper OCR Pipeline
This project extracts structured data from newspaper page images using a multi-stage pipeline:
1. ğŸ§¼ **Preprocessing** â€” binarizes, deskews, and denoises images
2. ğŸ§  **OCR Extraction** â€” applies multiple OCR models (Tesseract, etc.)
3. ğŸ¤– **Postprocessing with LLMs** â€” uses Ollama-based models to structure text into CSV
4. ğŸ“Š **Evaluation** â€” automatically scores LLM output against ground truth using F1, precision, recall
---

## ğŸ” Pipeline Overview

| Stage         | Description                                        | Output                            |
|---------------|----------------------------------------------------|-----------------------------------|
| Preprocessing | Enhances image quality for OCR                    | Cleaned `.tiff` images            |
| OCR           | Extracts raw text using multiple engines          | `.txt` files + log                |
| Postprocessing| Converts OCR text to structured CSV via LLMs      | `.csv` (or `.json`) per article   |
| Evaluation    | Measures similarity between predictions and gold labels (headline, content, etc.) | `.csv` with F1/precision/recall  |
---

## ğŸ“¦ Folder Structure

```
/data/images/                     â†’ Raw input images
/results/images/preprocessed/     â†’ Generated preprocessed image outputs
/results/txt/extracted/           â†’ Generated raw OCR `.txt` or `.json`
/results/csv/extracted/           â†’ Final structured CSV output
/results/csv/evaluation.csv       â†’ Evaluation results (F1, etc.)
/logs/                            â†’ Saved logs
/scripts/                         â†’ Core pipeline scripts
/docs/                            â†’ Script-specific documentation
/requirements/*.txt               â†’ Dependencies for each script
```

---

## ğŸš€ Quick Start

0. **Install dependencies**
```bash
pip3 install -r requirements/<script>_requirements.txt
```

1. **Run scripts independently**
```bash
python3 src/preprocess/preprocess.py
python3 src/ocr/ocr.py
python3 src/postprocess/postprocess.py
python3 src/evaluate/evaluate.py
```

**OR:**

1. **Run Pipeline in a single Bash-script**
```bash
chmod +x run_ocr_pipeline.sh
./run_ocr_pipeline.sh
```

## ğŸ“Š Evaluation Metrics

Each articleâ€™s `headline`, `subheadline`, and `content` fields are compared against gold labels using fuzzy string similarity (via `difflib`). Predictions are converted to binary matches and evaluated using:

- **Accuracy**
- **Precision**
- **Recall**
- **F1-score**

Results are saved to: `./results/csv/evaluation.csv`

## ğŸ“¢ Get quick help

1. **Get help for each script**
```bash
python <script>.py --help
```

2. **Run unit tests**
```bash
python <script>.py --test
```
---

## ğŸ§ª Requirements

- Python 3.10+
- Tesseract (installed locally)
- Ollama (installed locally and initialized)
- Dependencies (see `/requirements/*.txt`)

---

## ğŸ§¾ License
GPL License