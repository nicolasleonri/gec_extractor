# Newspaper OCR Pipeline
This project extracts structured data from newspaper page images using a multi-stage pipeline:
1. ğŸ§¼ **Preprocessing** â€” binarizes, deskews, and denoises images
2. ğŸ§  **OCR Extraction** â€” applies multiple OCR models (Tesseract, EasyOCR, etc.)
3. ğŸ¤– **Postprocessing with LLMs** â€” uses Ollama-based models to structure text into CSV

---

## ğŸ” Pipeline Overview

| Stage         | Description                                        | Output                            |
|---------------|----------------------------------------------------|-----------------------------------|
| Preprocessing | Enhances image quality for OCR                    | Cleaned `.tiff` images            |
| OCR           | Extracts raw text using multiple engines          | `.txt` files + log                |
| Postprocessing| Converts OCR text to structured CSV via LLMs      | `.csv` (or `.json`) per article   |

---

## ğŸ“¦ Folder Structure

```
/data/images/                     â†’ Raw input images
/results/images/preprocessed/     â†’ Preprocessed image outputs
/results/txt/extracted/           â†’ Raw OCR `.txt` or JSON
/results/csv/extracted/           â†’ Final structured CSV output
/logs/                            â†’ Processing logs
/scripts/                         â†’ Core pipeline code
/docs/                            â†’ Script-specific documentation
```

---

## ğŸš€ Quick Start

1. **Preprocess images**
```bash
python preprocess.py
```

2. **Run OCR with multiple engines**
```bash
python ocr.py
```

3. **Postprocess with LLMs**
```bash
python postprocess.py
```

4. **Run unit tests**
```bash
python <script>.py --test
```

---

## ğŸ§ª Requirements

- Python 3.10+
- OpenCV, NumPy, PaddleOCR, EasyOCR, docTR, keras-ocr
- Ollama (installed locally and running LLMs)

---

## ğŸ§¾ License
GPL License